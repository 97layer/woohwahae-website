#!/usr/bin/env python3
"""
97layerOS Chief Editor (CE) Agent
Phase 6.3: NotebookLM ë¸Œëœë“œ ê°€ì´ë“œ ì¿¼ë¦¬ ì—°ë™

Role:
- Content synthesis and editorial direction
- Transform insights + visuals into cohesive narratives
- Brand voice consistency â€” NotebookLM RAG ê¸°ë°˜ ì‹¤ì‹œê°„ ì°¸ì¡°
- Final content output (copy, captions, articles)

LLM: Gemini 2.5 Pro (Free tier)
Brand Reference: NotebookLM MCP (ì¿ í‚¤ ì¸ì¦ í•„ìš”, ì—†ìœ¼ë©´ fallback)
Queue: Autonomous task claiming via AgentWatcher
Output: Finalized content ready for CD approval

Author: 97layerOS Technical Director
Updated: 2026-02-16 (Phase 6.3 â€” NotebookLM ë¸Œëœë“œ ì—°ë™)
"""

import os
import sys
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime

# Project setup
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from core.system.agent_watcher import AgentWatcher
from core.system.queue_manager import Task
from core.system.agent_logger import get_logger

try:
    import google.genai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

logger = logging.getLogger(__name__)

# Brand OS ë¬¸ì„œ ë¡œë”© (NotebookLM ì—°ê²° ë¶ˆê°€ ì‹œ primary source)
BRAND_DIR = PROJECT_ROOT / "directives" / "brand"

def _load_brand_directives() -> str:
    """brand/voice_tone.md + brand/content_system.md ë¡œë“œ â†’ CE ë¸Œëœë“œ ë³´ì´ìŠ¤"""
    docs = []
    for filename in ["voice_tone.md", "content_system.md"]:
        filepath = BRAND_DIR / filename
        try:
            content = filepath.read_text(encoding="utf-8")
            # í† í° ì ˆì•½: ì²˜ìŒ 1500ì
            docs.append(content[:1500])
        except FileNotFoundError:
            pass
    if docs:
        return "\n---\n".join(docs)
    # ìµœì†Œ fallback
    return (
        "97layer ë¸Œëœë“œ ë³´ì´ìŠ¤:\n"
        "- í†¤: ì‚¬ìƒ‰ì , ì ˆì œëœ, ë°€ë„ ìˆëŠ”\n"
        "- ê¸ˆì§€ì–´: ëŒ€ë°•, ê¿€íŒ, í•«, íŠ¸ë Œë””, ê³¼ì¥ í˜•ìš©ì‚¬\n"
        "- í—ˆìš©ì–´: ë³¸ì§ˆ, ê¸°ë¡, ìˆœê°„, í”ì , ì ˆì œ, ê³ ìš”í•¨\n"
        "- ìº¡ì…˜: 50-100ë‹¨ì–´. ì—ì„¸ì´: 5000-8000ì\n"
        "- ì–´ì¡°: Archive=í•œë‹¤ì²´, Magazine=í•©ë‹ˆë‹¤ì²´"
    )


class ChiefEditor:
    """
    Chief Editor Agent - Content Synthesis & Editorial Direction

    Capabilities:
    - Synthesize SA analysis + AD visuals into cohesive content
    - Write copy in 97layer brand voice (NotebookLM RAG ì°¸ì¡°)
    - Create social media captions, articles, newsletters
    - Editorial QA before CD review
    """

    def __init__(self, agent_id: str = "ce-worker-1", api_key: Optional[str] = None):
        self.agent_id = agent_id
        self.agent_type = "CE"
        self._brand_voice_cache: Optional[str] = None

        # AgentLogger ì´ˆê¸°í™”
        self.logger = get_logger("ce", PROJECT_ROOT)
        self.logger.idle("CE Agent ì‹œì‘")

        if not GEMINI_AVAILABLE:
            raise ImportError("google-generativeai required")

        api_key = api_key or os.getenv('GOOGLE_API_KEY')
        if not api_key:
            raise ValueError("GOOGLE_API_KEY not found")

        self.client = genai.Client(api_key=api_key)
        self._model_name = 'gemini-2.5-pro'

        # NotebookLM ë¸Œë¦¿ì§€ (ì„ íƒì  â€” ì—†ì–´ë„ ë™ì‘)
        self.nlm = None
        try:
            from core.system.notebooklm_bridge import get_bridge, is_available
            if is_available():
                self.nlm = get_bridge()
                print(f"âœ… {self.agent_id}: NotebookLM ë¸Œëœë“œ RAG ì—°ê²°ë¨")
            else:
                print(f"âš ï¸  {self.agent_id}: NotebookLM ë¯¸ì—°ê²° â€” fallback ë¸Œëœë“œ ë³´ì´ìŠ¤ ì‚¬ìš©")
        except Exception as e:
            logger.warning("NotebookLM ì´ˆê¸°í™” ì‹¤íŒ¨: %s", e)

        print(f"CE: ì¤€ë¹„ë¨.")

    def _get_brand_voice(self) -> str:
        """
        NotebookLMì—ì„œ 97layer ë¸Œëœë“œ ë³´ì´ìŠ¤ ì°¸ì¡° ê°€ì ¸ì˜¤ê¸°.
        ì„¸ì…˜ ë‚´ ì²« í˜¸ì¶œ ì‹œë§Œ ì¿¼ë¦¬, ì´í›„ ìºì‹œ ì‚¬ìš©.
        NotebookLM ì—°ê²° ë¶ˆê°€ ì‹œ fallback ë°˜í™˜.
        """
        if self._brand_voice_cache:
            return self._brand_voice_cache

        if self.nlm:
            try:
                logger.info("%s: NotebookLM ë¸Œëœë“œ ë³´ì´ìŠ¤ ì¿¼ë¦¬ ì¤‘...", self.agent_id)
                result = self.nlm.query_knowledge_base(
                    "97layer ë¸Œëœë“œ ë³´ì´ìŠ¤ì™€ WOOHWAHAE í†¤ì•¤ë§¤ë„ˆ ê°€ì´ë“œ. "
                    "ê¸ˆì§€ì–´, í—ˆìš©ì–´, ë¬¸ì¥ ìŠ¤íƒ€ì¼, ì¸ì¹­, ì‹œì œ ê·œì¹™ì„ ìš”ì•½í•´ì¤˜."
                )
                if result and len(result) > 50:
                    self._brand_voice_cache = result
                    logger.info("%s: NotebookLM ë¸Œëœë“œ ë³´ì´ìŠ¤ ìºì‹œ ì™„ë£Œ (%dì)", self.agent_id, len(result))
                    return self._brand_voice_cache
            except Exception as e:
                logger.warning("%s: NotebookLM ì¿¼ë¦¬ ì‹¤íŒ¨, fallback ì‚¬ìš©: %s", self.agent_id, e)

        self._brand_voice_cache = _load_brand_directives()
        return self._brand_voice_cache

    def write_content(self, analysis: Dict[str, Any], visual_concept: Dict[str, Any],
                      retry_count: int = 0, feedback: str = "", previous_output: Dict = None) -> Dict[str, Any]:
        """
        SA ë¶„ì„ + AD ë¹„ì£¼ì–¼ ì»¨ì…‰ì„ ê¸°ë°˜ìœ¼ë¡œ ì½˜í…ì¸  ì‘ì„±.
        ì¸ìŠ¤íƒ€ê·¸ë¨ íŒ¨í‚¤ì§€ + ì•„ì¹´ì´ë¸Œ ì—ì„¸ì´ ì´ì¤‘ í¬ë§· ìƒì„±.

        Args:
            analysis: SA strategic analysis
            visual_concept: AD visual concept
            retry_count: ì¬ì‘ì—… íšŸìˆ˜ (CD ê±°ì ˆ ë˜ëŠ” Ralph ì ìˆ˜ ë¯¸ë‹¬)
            feedback: ì´ì „ ê±°ì ˆ í”¼ë“œë°± (ì¬ì‘ì—… ì‹œ)
            previous_output: ì´ì „ ê²°ê³¼ë¬¼ (ì¬ì‘ì—… ì°¸ê³ ìš©)

        Returns:
            {
              instagram_caption, hashtags, archive_essay,
              headline, tone, ...
            }
        """
        signal_id = analysis.get('signal_id', 'unknown')
        print(f"CE: {signal_id} ì´ˆì•ˆ ì‘ì—…." + (f" (ì¬ì‘ì—… {retry_count}íšŒì°¨)" if retry_count > 0 else ""))

        # ë¸Œëœë“œ ë³´ì´ìŠ¤ ì°¸ì¡° (NotebookLM ë˜ëŠ” fallback)
        brand_voice = self._get_brand_voice()
        brand_source = "NotebookLM RAG" if self.nlm else "Brand OS directives"
        logger.info("%s: ë¸Œëœë“œ ë³´ì´ìŠ¤ ì¶œì²˜ â€” %s", self.agent_id, brand_source)

        # ì¬ì‘ì—… ì»¨í…ìŠ¤íŠ¸
        retry_context = ""
        if retry_count > 0 and feedback:
            retry_context = f"""
**ì´ì „ í”¼ë“œë°± (ë°˜ë“œì‹œ ë°˜ì˜):**
{feedback}

"""
        if previous_output:
            retry_context += f"""**ì´ì „ ì¶œë ¥ (ê°œì„  í•„ìš”):**
- ì¸ìŠ¤íƒ€ ìº¡ì…˜: {previous_output.get('instagram_caption', 'N/A')[:100]}
- ì—ì„¸ì´ ì¼ë¶€: {str(previous_output.get('archive_essay', 'N/A'))[:200]}

"""

        prompt = f"""ë‹¹ì‹ ì€ Chief Editor(CE)ì…ë‹ˆë‹¤.
WOOHWAHAE ìŠ¬ë¡œìš° ë¼ì´í”„ ì•„í‹€ë¦¬ì—ì˜ ë¸Œëœë“œ ëª©ì†Œë¦¬ë¡œ ì½˜í…ì¸ ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

**ì „ëµ ë¶„ì„ (SA ì œê³µ):**
- ì£¼ì œ: {', '.join(analysis.get('themes', []))}
- í•µì‹¬ ì¸ì‚¬ì´íŠ¸: {'; '.join(analysis.get('key_insights', []))}
- ìš”ì•½: {analysis.get('summary', '')}

**ë¹„ì£¼ì–¼ ì»¨ì…‰ (AD ì œê³µ):**
- ì œëª©: {visual_concept.get('concept_title', '(ì—†ìŒ)')}
- ë¬´ë“œ: {visual_concept.get('visual_mood', '(ì—†ìŒ)')}
- ë¸Œëœë“œ ì •ë ¬: {visual_concept.get('brand_alignment', '(ì—†ìŒ)')}

**97layer ë¸Œëœë“œ ë³´ì´ìŠ¤ ê°€ì´ë“œ:**
{brand_voice}

{retry_context}
ìœ„ ê°€ì´ë“œë¥¼ ì² ì €íˆ ë”°ë¼ **ë‘ ê°€ì§€ í¬ë§·**ìœ¼ë¡œ ì½˜í…ì¸ ë¥¼ ì‘ì„±í•˜ì„¸ìš”:

1. **Instagram íŒ¨í‚¤ì§€**: ë°œí–‰ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ í˜•íƒœ
2. **Archive Essay**: Notion/ë¸”ë¡œê·¸ìš© ë¡±í¼ ì—ì„¸ì´

ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
{{
  "instagram_caption": "ì¸ìŠ¤íƒ€ê·¸ë¨ ìº¡ì…˜ (í•œêµ­ì–´, 150ì ì´ë‚´, ë¸Œëœë“œ í†¤ ì² ì €íˆ ì¤€ìˆ˜, ì´ëª¨ì§€ ìµœì†Œí™”)",
  "hashtags": "#woohwahae #slowlife #ì•„ì¹´ì´ë¸Œ (ê´€ë ¨ í•œêµ­ì–´ í•´ì‹œíƒœê·¸ 5-8ê°œ)",
  "archive_essay": "ì•„ì¹´ì´ë¸Œ ì—ì„¸ì´ (í•œêµ­ì–´, 500-800ì, ì‚¬ìƒ‰ì  ë¡±í¼, ë‹¨ë½ êµ¬ë¶„ í¬í•¨, ëŠë¦¬ê³  ê¹Šì€ í†¤)",
  "headline": "í—¤ë“œë¼ì¸ (10-20ì)",
  "tone": "contemplative|reflective|grounded ì¤‘ í•˜ë‚˜",
  "brand_voice_source": "{brand_source}"
}}

í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­:
- instagram_caption: ë°˜ë“œì‹œ 150ì ì´ë‚´. ì§ê´€ì ì´ê³  í•µì‹¬ë§Œ.
- hashtags: #woohwahae ë°˜ë“œì‹œ í¬í•¨
- archive_essay: ë°˜ë“œì‹œ 500ì ì´ìƒ. ì§ˆë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬ ê¶Œì¥.
- ê¸ˆì§€ì–´: í˜ì‹ , íŠ¸ë Œë“œ, ìµœì‹ , í˜ëª…ì , ì••ë„ì 

ìœ íš¨í•œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”.
"""

        try:
            response = self.client.models.generate_content(
                model=self._model_name,
                contents=[prompt]
            )
            content_text = response.text

            # JSON íŒŒì‹±
            if '```json' in content_text:
                json_start = content_text.find('```json') + 7
                json_end = content_text.find('```', json_start)
                json_text = content_text[json_start:json_end].strip()
            elif '```' in content_text:
                json_start = content_text.find('```') + 3
                json_end = content_text.find('```', json_start)
                json_text = content_text[json_start:json_end].strip()
            else:
                json_text = content_text.strip()

            content = json.loads(json_text)

            content.update({
                'signal_id': signal_id,
                'written_by': self.agent_id,
                'written_at': datetime.now().isoformat(),
                'model': self._model_name,
                'brand_voice_source': brand_source,
                'retry_count': retry_count,
                'status': 'draft_for_cd',
            })

            caption_len = len(content.get('instagram_caption', ''))
            essay_len = len(content.get('archive_essay', ''))
            print(f"CE: ì´ˆì•ˆ ì™„ë£Œ. ìº¡ì…˜ {caption_len}ì, ì—ì„¸ì´ {essay_len}ì.")
            return content

        except Exception as e:
            logger.error("%s: ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: %s", self.agent_id, e)
            return {'signal_id': signal_id, 'error': str(e), 'status': 'failed'}

    def process_task(self, task: Task) -> Dict[str, Any]:
        task_type = task.task_type
        payload = task.payload

        print(f"CE: {task.task_id} ({task_type})")

        if task_type == 'write_content':
            # Orchestratorì—ì„œ ì˜¤ëŠ” ìƒˆ payload êµ¬ì¡° ì§€ì›
            # payloadì— sa_resultê°€ ìˆìœ¼ë©´ Orchestrator ê²½ìœ 
            sa_result = payload.get('sa_result', payload.get('analysis', {}))
            visual = payload.get('visual_concept', payload.get('ad_result', {}).get('visual_concept', {}))

            # ì¬ì‘ì—… íŒŒë¼ë¯¸í„°
            retry_count = payload.get('retry_count', 0)
            feedback = payload.get('feedback', payload.get('cd_feedback', ''))
            previous_output = payload.get('previous_output', None)

            result = self.write_content(
                analysis=sa_result,
                visual_concept=visual,
                retry_count=retry_count,
                feedback=feedback,
                previous_output=previous_output
            )
            # SA ì „ëµ ì ìˆ˜ë¥¼ resultì— í¬í•¨ (Ralph ì±„ì ìš©)
            result['sa_strategic_score'] = sa_result.get('strategic_score', 0)
            return {'status': 'completed', 'task_id': task.task_id, 'result': result}

        elif task_type == 'write_corpus_essay':
            # Gardenerê°€ íŠ¸ë¦¬ê±°í•œ corpus ê¸°ë°˜ ì—ì„¸ì´ ì‘ì„±
            # ë‹¨ì¼ ì‹ í˜¸ê°€ ì•„ë‹Œ êµ°ì§‘ ì „ì²´ RAG â†’ Magazine B ìŠ¤íƒ€ì¼ ë¡±í¼
            result = self._write_corpus_essay(payload)

            # ContentPublisher í˜¸ì¶œ (í™ˆí˜ì´ì§€ ë°œí–‰)
            if result and not result.get('error'):
                try:
                    from core.system.content_publisher import ContentPublisher
                    from pathlib import Path
                    publisher = ContentPublisher(base_path=Path(__file__).parent.parent.parent)

                    pub_payload = {
                        'signal_id': payload.get('theme', 'corpus').replace(' ', '_'),
                        'ce_result': result,
                        'mode': 'corpus_essay',
                        'essay_title': result.get('essay_title', ''),
                        'instagram_caption': result.get('instagram_caption', ''),
                        'archive_essay': result.get('archive_essay', ''),
                        'pull_quote': result.get('pull_quote', ''),
                        'carousel_slides': result.get('carousel_slides', []),
                        'telegram_summary': result.get('telegram_summary', ''),
                        'sa_result': {'themes': [payload.get('theme', '')]},
                        'ad_result': {},
                    }
                    pub_result = publisher.publish(pub_payload)
                    result['published'] = pub_result.get('status') in ('success', 'published')
                    result['website_published'] = pub_result.get('website_published', False)
                    result['telegram_sent'] = pub_result.get('telegram_sent', False)
                    tg = 'âœ“' if result['telegram_sent'] else 'âœ—'
                    ctype = result.get('content_type', 'essay')
                    print(f"CE: í™ˆí˜ì´ì§€ ë°œí–‰ ì™„ë£Œ â€” {result.get('essay_title', 'N/A')} [{ctype}] | telegram={tg}")
                except Exception as e:
                    print(f"CE: í™ˆí˜ì´ì§€ ë°œí–‰ ì‹¤íŒ¨ â€” {e}")
                    result['published'] = False

            return {'status': 'completed', 'task_id': task.task_id, 'result': result}

        else:
            return {'status': 'failed', 'error': f"Unknown task type: {task_type}"}

    def _write_corpus_essay(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Corpus êµ°ì§‘ ê¸°ë°˜ ì›ì†ŒìŠ¤ ë©€í‹°ìœ ì¦ˆ ì½˜í…ì¸  ìƒì„±.

        í•˜ë‚˜ì˜ Gemini í˜¸ì¶œë¡œ 5ê°œ í¬ë§· ë™ì‹œ ìƒì„±:
          1. archive_essay     â€” ë¡±í¼ ì—ì„¸ì´ (800~1200ì) â†’ woohwahae.kr/archive/
          2. instagram_caption â€” ìº¡ì…˜ (150ì ì´ë‚´) â†’ ì¸ìŠ¤íƒ€ê·¸ë¨ ë‹¨ì¼ í”¼ë“œ
          3. carousel_slides   â€” 3~5ì¥ í…ìŠ¤íŠ¸ ìŠ¬ë¼ì´ë“œ â†’ ì¸ìŠ¤íƒ€ê·¸ë¨ ìºëŸ¬ì…€
          4. telegram_summary  â€” 3ì¤„ ìš”ì•½ â†’ ë´‡ í‘¸ì‹œ ì•Œë¦¼
          5. pull_quote        â€” í•µì‹¬ 1ë¬¸ì¥ â†’ ì›¹ì‚¬ì´íŠ¸ íˆì–´ë¡œ/about ì¸ìš©êµ¬

        ì›ì¹™: í¬ë§·ì´ ë‹¤ë¥¼ ë¿ ë™ì¼í•œ ë³¸ì§ˆì—ì„œ íŒŒìƒ. ì¬ê°€ê³µ ì•„ë‹Œ íŒŒìƒ.
        """
        theme = payload.get("theme", "")
        rag_context = payload.get("rag_context", [])
        entry_count = payload.get("entry_count", 0)
        instruction = payload.get("instruction", "")
        content_type = payload.get("content_type", "archive")
        content_category = payload.get("content_category", "")

        # AgentLogger: ì—ì„¸ì´ ì‘ì„± ì‹œì‘
        self.logger.think(f"ì—ì„¸ì´ ì‘ì„± ì¤‘: {theme}")

        # essay: archive or essay type â†’ í•œë‹¤ì²´, ë…ë°±, 300-800ì
        # journal: magazine or journal type â†’ í•©ë‹ˆë‹¤ì²´, ~~~í•˜ëŠ” ë²•, 1200-3000ì
        is_journal = content_type in ("magazine", "journal")

        if is_journal:
            tone_guide = (
                "ë¬¸ì²´: í•©ë‹ˆë‹¤ì²´. í˜•ì‹: ~~~í•˜ëŠ” ë²• / ì•ˆë‚´í˜•. "
                "êµ¬ì¡°: ë¦¬ë“œ(ë„ì… ìš”ì•½) â†’ ë³¸ë¬¸(ë‹¨ê³„ë³„ ì„¤ëª…) â†’ ì‹¤ì²œ(ì˜¨í™”í•œ ì œì•ˆ). "
                "ê¸¸ì´: 1200-3000ì. "
                "ë§ˆë¬´ë¦¬: ë…ìê°€ ì‹¤ì²œ ê°€ëŠ¥í•œ ì œì•ˆ. ê¸ˆì§€: ìê¸°ì¤‘ì‹¬ ê´€ì°°, ëª¨í˜¸í•œ ê²°ë¡ ."
            )
            essay_length_spec = "1200~3000ì. ë¦¬ë“œ+ë³¸ë¬¸+ì‹¤ì²œ êµ¬ì¡°."
        else:
            tone_guide = (
                "ë¬¸ì²´: í•œë‹¤ì²´. í˜•ì‹: ë…ë°±, ê´€ì°°ì ì‹œì . "
                "êµ¬ì¡°: Hook(ì—­ì„¤/ì„ ì–¸) â†’ Story(ê°œì¸â†’ë³´í¸) â†’ Core(í†µì°°) â†’ Echo(Hook ë³€ì£¼). "
                "ê¸¸ì´: 300-800ì. "
                "ë§ˆë¬´ë¦¬: ê²°ë¡  ì—†ì´ ì—¬ìš´. ì—´ë¦° ì§ˆë¬¸ ë˜ëŠ” ì—¬ë°±. ê¸ˆì§€: ê°•í•œ í˜¸ì†Œ, í–‰ë™ ìœ ë„."
            )
            essay_length_spec = "300~800ì. Hook-Story-Core-Echo êµ¬ì¡°."

        # RAG ì»¨í…ìŠ¤íŠ¸ ì§ë ¬í™”
        context_text = ""
        for i, entry in enumerate(rag_context, 1):
            context_text += f"\n[{i}] {entry.get('captured_at', '')[:10]} | {entry.get('signal_type', '')}\n"
            context_text += f"ìš”ì•½: {entry.get('summary', '')}\n"
            insights = entry.get('key_insights', [])
            if insights:
                context_text += f"ì¸ì‚¬ì´íŠ¸: {' / '.join(str(x) for x in insights[:3])}\n"

        category_hint = f"\nì¹´í…Œê³ ë¦¬: {content_category}" if content_category else ""

        prompt = f"""ë„ˆëŠ” WOOHWAHAEì˜ í¸ì§‘ì¥ì´ë‹¤.

ì£¼ì œ: {theme}{category_hint}
íƒ€ì…: {"Journal (í•©ë‹ˆë‹¤ì²´, ì•ˆë‚´í˜•)" if is_journal else "Essay (í•œë‹¤ì²´, ë…ë°±í˜•)"}
ì‹ í˜¸ ìˆ˜: {entry_count}ê°œ

ì•„ë˜ëŠ” ì´ ì£¼ì œì™€ ê´€ë ¨í•´ ì‹œê°„ì„ ë‘ê³  ìŒ“ì¸ ì‹ í˜¸ë“¤ì˜ ìš”ì•½ì´ë‹¤:
{context_text}

ì´ ì‹ í˜¸ë“¤ì˜ íë¦„ì—ì„œ ë³¸ì§ˆì„ ì½ì–´ë‚´ê³ , ì•„ë˜ 5ê°œ í¬ë§·ì„ ë™ì‹œì— ë§Œë“¤ì–´ë¼.
ëª¨ë‘ ê°™ì€ ë³¸ì§ˆì—ì„œ íŒŒìƒëœë‹¤. ì¬ê°€ê³µì´ ì•„ë‹Œ íŒŒìƒì´ë‹¤.

ê³µí†µ ê·œì¹™:
- í•œêµ­ì–´
- ì´ëª¨ì§€ ì™„ì „ ê¸ˆì§€
- ë³¼ë“œ, í—¤ë” ì‚¬ìš© ê¸ˆì§€
- WOOHWAHAE í†¤: {tone_guide}

ì‘ë‹µ í˜•ì‹ (JSON):
{{
  "essay_title": "ì œëª© (10ì ì´ë‚´, ëª…ì‚¬í˜•)",
  "pull_quote": "ì´ ê¸€ ì „ì²´ë¥¼ ê´€í†µí•˜ëŠ” í•µì‹¬ ë¬¸ì¥ 1ê°œ (30ì ì´ë‚´). ì›¹ì‚¬ì´íŠ¸ íˆì–´ë¡œì— ì¨ë„ ë  ë§Œí¼ ë°€ë„ ìˆê²Œ.",
  "archive_essay": "ì—ì„¸ì´ ë³¸ë¬¸. {essay_length_spec} ë‹¨ë½ ì‚¬ì´ ë¹ˆ ì¤„.",
  "instagram_caption": "ì¸ìŠ¤íƒ€ê·¸ë¨ ìº¡ì…˜. 150ì ì´ë‚´. ì—ì„¸ì´ì˜ í•µì‹¬ì„ ì••ì¶•. ë§ˆì§€ë§‰ ì¤„ì€ ì—¬ë°±ì„ ì£¼ëŠ” í•œ ë¬¸ì¥.",
  "carousel_slides": [
    "ìŠ¬ë¼ì´ë“œ 1: ë„ì… ë¬¸ì¥ (30ì ì´ë‚´)",
    "ìŠ¬ë¼ì´ë“œ 2: í•µì‹¬ ê´€ì°° (30ì ì´ë‚´)",
    "ìŠ¬ë¼ì´ë“œ 3: ë§¥ë½ ë˜ëŠ” ì—­ì„¤ (30ì ì´ë‚´)",
    "ìŠ¬ë¼ì´ë“œ 4: ë§ˆë¬´ë¦¬ ë˜ëŠ” ì§ˆë¬¸ (30ì ì´ë‚´)"
  ],
  "telegram_summary": "ë´‡ í‘¸ì‹œ ì•Œë¦¼ìš© 3ì¤„ ìš”ì•½. ê° ì¤„ 40ì ì´ë‚´. ì²« ì¤„: ì œëª©. ë‘˜ì§¸ ì¤„: í•µì‹¬. ì…‹ì§¸ ì¤„: ë§í¬ ìœ ë„.",
  "theme": "{theme}",
  "content_category": "{content_category}",
  "content_type": "{"journal" if is_journal else "essay"}",
  "entry_count": {entry_count}
}}

JSONë§Œ ì¶œë ¥."""

        try:
            import google.genai as genai
            import os, re
            client = genai.Client(api_key=os.getenv('GOOGLE_API_KEY'))
            response = client.models.generate_content(
                model='gemini-2.5-pro',
                contents=[prompt]
            )
            text = response.text.strip()
            match = re.search(r'\{.*\}', text, re.DOTALL)
            if match:
                result = json.loads(match.group())
                formats = [k for k in ['archive_essay', 'instagram_caption', 'carousel_slides',
                                        'telegram_summary', 'pull_quote'] if k in result]
                print(f"CE: ì›ì†ŒìŠ¤ ë©€í‹°ìœ ì¦ˆ ì™„ë£Œ â€” {theme} | íƒ€ì…: {content_type} | í¬ë§·: {', '.join(formats)}")
            else:
                result = {
                    "archive_essay": text,
                    "essay_title": theme,
                    "theme": theme,
                    "entry_count": entry_count
                }

            # â”€â”€ HTML ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            try:
                self._save_essay_html(result, theme)
            except Exception as html_e:
                # HTML ì €ì¥ ì‹¤íŒ¨ëŠ” ì—ì„¸ì´ ìƒì„± ê²°ê³¼ì— ì˜í–¥ ì—†ìŒ
                print(f"CE: HTML ì €ì¥ ì‹¤íŒ¨ (ë¬´ì‹œ) â€” {html_e}")

            # â”€â”€ NotebookLM Essay Archive ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if self.nlm:
                try:
                    self.nlm.add_essay_to_archive({
                        'essay_title': result.get('essay_title', theme),
                        'theme': theme,
                        'archive_essay': result.get('archive_essay', ''),
                        'pull_quote': result.get('pull_quote', ''),
                        'instagram_caption': result.get('instagram_caption', ''),
                        'issue_num': result.get('issue_num', ''),
                    })
                    print(f"CE: NotebookLM Essay Archive ì €ì¥ ì™„ë£Œ â€” {result.get('essay_title', theme)}")
                except Exception as nlm_e:
                    print(f"CE: NotebookLM ì €ì¥ ì‹¤íŒ¨ (ë¬´ì‹œ) â€” {nlm_e}")

            return result

        except Exception as e:
            print(f"CE: corpus ì—ì„¸ì´ ì‹¤íŒ¨ â€” {e}")
            return {"error": str(e), "theme": theme}

    def _save_essay_html(self, result: dict, theme: str):
        """CE ì—ì„¸ì´ ê²°ê³¼ë¥¼ website/archive/issue-NNN-slug/index.html ë¡œ ì €ì¥."""
        import re as _re
        from datetime import datetime as _dt
        from pathlib import Path as _Path

        # AgentLogger: HTML ì €ì¥ ì‹œì‘
        self.logger.write(f"HTML ìƒì„± ì¤‘: {theme}")

        # env_validator ê²½ìœ  ë‹¨ì¼ ì§„ì…ì 
        try:
            from core.system.env_validator import get_project_root, get_site_base_url
            PROJECT_ROOT = _Path(get_project_root())
        except Exception:
            PROJECT_ROOT = _Path(__file__).resolve().parent.parent.parent

        instagram_url = os.getenv('INSTAGRAM_URL', 'https://instagram.com/woohwahae')
        archive_dir = PROJECT_ROOT / 'website' / 'archive'

        # â”€â”€ ì´ìŠˆ ë²ˆí˜¸ ìë™ ê³„ì‚° â”€â”€
        existing = sorted([
            d for d in archive_dir.iterdir()
            if d.is_dir() and _re.match(r'issue-\d+', d.name)
        ])
        # issue-00 ~ issue-008 í˜•íƒœ ëª¨ë‘ í¬í•¨í•´ì„œ ìµœëŒ“ê°’ ì¶”ì¶œ
        max_num = 0
        for d in existing:
            m = _re.match(r'issue-0*(\d+)', d.name)
            if m:
                max_num = max(max_num, int(m.group(1)))
        next_num = max_num + 1
        issue_num_str = f"{next_num:03d}"  # 009, 010 ...

        # â”€â”€ slug ìƒì„± (í…Œë§ˆ â†’ ì†Œë¬¸ì ì˜ë¬¸ slug) â”€â”€
        # ë‹¨ì–´ ë‹¨ìœ„ ë§¤í•‘ â€” ë³µí•© í…Œë§ˆë„ ì²˜ë¦¬ (ì²« ë²ˆì§¸ ë§¤ì¹­ í‚¤ì›Œë“œ ì‚¬ìš©)
        _word_slug_map = {
            'ì¡°ìš©í•œì§€ëŠ¥': 'quiet-intelligence', 'ìŠ¬ë¡œìš°ë¼ì´í”„': 'slow-life',
            'ì—¬ë°±': 'negative-space', 'ê¸°ë¡': 'record',
            'ê°ê°': 'sensory', 'ì¹¨ë¬µ': 'silence',
            'ë¬¼ì„±': 'materiality', 'ì¼ìƒ': 'daily',
            'ë¯¸ìš©': 'beauty', 'ì •ì‹ ê±´ê°•': 'mental-health', 'ì •ì‹ ': 'mental',
            'ëŒë´„': 'care', 'ê´€ê³„': 'relationship', 'ì‹œê°„': 'time',
            'ê³µê°„': 'space', 'ìŒì‹': 'food', 'ìŒì•…': 'music',
            'ë…ì„œ': 'reading', 'ê¸€ì“°ê¸°': 'writing', 'ì‚¬ì§„': 'photo',
            'ì—¬í–‰': 'travel', 'ì‚°ì±…': 'walk', 'ê³„ì ˆ': 'season',
            'ë¹›': 'light', 'ìƒ‰': 'color', 'ì§ˆê°': 'texture',
            'ë³¸ì§ˆ': 'essence', 'ì„ íƒ': 'choice', 'ì§‘ì¤‘': 'focus',
            'ëŠë¦¼': 'slow', 'ë¹„ì›€': 'empty', 'ì±„ì›€': 'fill',
            'ìŠµê´€': 'habit', 'ë£¨í‹´': 'routine', 'ì˜ì‹': 'ritual',
            'ëª¸': 'body', 'ë§ˆìŒ': 'mind', 'ì˜ì„±': 'spirit',
        }
        theme_key = theme.replace(' ', '').replace('ì˜', '').replace('ê³¼', '').replace('ì™€', '')
        slug = None
        # ì •í™• ë§¤ì¹­ ìš°ì„ 
        for k, v in _word_slug_map.items():
            if k in theme_key:
                slug = v
                break
        if not slug:
            # ASCII í…Œë§ˆëŠ” ê·¸ëŒ€ë¡œ slugí™”
            ascii_slug = _re.sub(r'[^\w-]', '', theme.lower().replace(' ', '-'))
            slug = ascii_slug if ascii_slug and ascii_slug[0].isascii() else 'essay'
        slug = slug[:30]

        folder_name = f"issue-{issue_num_str}-{slug}"
        issue_dir = archive_dir / folder_name
        issue_dir.mkdir(parents=True, exist_ok=True)

        essay_title = result.get('essay_title', theme)
        pull_quote = result.get('pull_quote', '')
        archive_essay = result.get('archive_essay', '')
        today = _dt.now().strftime('%Y.%m.%d')
        content_type_label = result.get('content_type', 'essay').capitalize()
        content_category_label = result.get('content_category', '')

        # â”€â”€ ì—ì„¸ì´ ë³¸ë¬¸ â†’ HTML ë‹¨ë½ ë³€í™˜ â”€â”€
        paragraphs = [p.strip() for p in archive_essay.split('\n\n') if p.strip()]
        para_html = ''
        for i, p in enumerate(paragraphs):
            # ì¤‘ê°„ì— <hr> í•œ ë²ˆ ì‚½ì… (ì ˆë°˜ ì§€ì )
            if i == len(paragraphs) // 2:
                para_html += '            <hr class="article-divider">\n\n'
            if i == len(paragraphs) - 1:
                # ë§ˆì§€ë§‰ ë‹¨ë½ì€ closing ìŠ¤íƒ€ì¼
                para_html += f'            <p class="article-closing fade-in">\n                {p}\n            </p>\n\n'
            else:
                para_html += f'            <p class="fade-in">\n                {p}\n            </p>\n\n'

        html = f"""<!DOCTYPE html>
<html lang="ko">

<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" href="../../assets/img/symbol.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Issue {issue_num_str} â€” {essay_title}. {pull_quote}">
  <title>Issue {issue_num_str}: {essay_title} â€” WOOHWAHAE Archive</title>
  <link rel="manifest" href="/manifest.webmanifest">
  <meta name="theme-color" content="#FAFAF7">
  <link rel="icon" href="../../assets/img/symbol.jpg" type="image/jpeg">
  <link rel="stylesheet" href="../../assets/css/style.css">
</head>

<body>

    <nav>
        <a href="/" class="nav-brand" aria-label="WOOHWAHAE">
            <img src="../../assets/media/brand/symbol.png" alt="WOOHWAHAE" class="nav-symbol">
        </a>
        <ul class="nav-links" id="nav-links">
            <li><a href="../../archive/" class="active">Archive</a></li>
            <li><a href="../../practice/">Practice</a></li>
            <li><a href="../../about/">About</a></li>
        </ul>
        <button class="nav-toggle" id="nav-toggle" aria-label="ë©”ë‰´" aria-expanded="false">
            <span></span><span></span>
        </button>
    </nav>

    <div class="article-container">

        <header class="article-header">
            <p class="article-meta fade-in">Issue {issue_num_str} &nbsp;Â·&nbsp; {content_category_label + ' Â· ' if content_category_label else ''}{content_type_label} &nbsp;Â·&nbsp; {today}</p>
            <h1 class="article-title fade-in">{essay_title}</h1>
            <p class="article-subtitle fade-in">{pull_quote}</p>
        </header>

        <div class="article-body">

{para_html}
        </div>

    </div>

    <footer class="site-footer">
        <div class="footer-inner">
            <p class="footer-brand">WOOHWAHAE</p>
            <nav class="footer-nav">
                <a href="../../archive/">Archive</a>
                <a href="../../practice/">Practice</a>
                <a href="../../about/">About</a>
                <a href="{instagram_url}" target="_blank" rel="noopener">Instagram</a>
            </nav>
            </div>
        </div>
        <p class="footer-copy">&copy; 2026 WOOHWAHAE. All rights reserved.</p>
    </footer>

    <script src="../../assets/js/main.js"></script>
</body>
</html>"""

        html_path = issue_dir / 'index.html'
        html_path.write_text(html, encoding='utf-8')
        print(f"CE: HTML ì €ì¥ ì™„ë£Œ â€” {html_path.relative_to(PROJECT_ROOT)}")
        print(f"CE: Issue {issue_num_str} '{essay_title}' â†’ archive/{folder_name}/")

        # AgentLogger: ì‘ì—… ì™„ë£Œ
        self.logger.done(f"Issue {issue_num_str}: {essay_title}")

    def start_watching(self, interval: int = 5):
        watcher = AgentWatcher(agent_type=self.agent_type, agent_id=self.agent_id)
        nlm_status = "ì—°ê²°ë¨" if self.nlm else "fallback"
        print(f"CE: í ê°ì‹œ ì‹œì‘.")
        print(f"   LLM: Gemini 2.5 Pro")
        print(f"   Brand Voice: NotebookLM RAG ({nlm_status})")
        print(f"   Tasks: write_content")
        print()
        watcher.watch(callback=self.process_task, interval=interval)


if __name__ == '__main__':
    import argparse
    from core.system.env_validator import validate_env
    validate_env("ce_agent")

    parser = argparse.ArgumentParser(description='97layerOS Chief Editor Agent')
    parser.add_argument('--agent-id', default='ce-worker-1')
    parser.add_argument('--interval', type=int, default=5)
    parser.add_argument('--test', action='store_true')
    args = parser.parse_args()

    agent = ChiefEditor(agent_id=args.agent_id)

    if args.test:
        print("\nğŸ§ª Test Mode: Content Writing\n" + "=" * 50)
        test_analysis = {
            'signal_id': 'test_001',
            'themes': ['AIì™€ ì°½ì‘', 'ëŠë¦° ì‚¶'],
            'key_insights': ['AIëŠ” ë°˜ë³µì„ ì œê±°í•˜ê³  ì°½ì‘ì— ì§‘ì¤‘í•˜ê²Œ í•œë‹¤', 'ì†ë„ë³´ë‹¤ ê¹Šì´ê°€ ë” ì˜¤ë˜ ë‚¨ëŠ”ë‹¤'],
            'summary': 'AIëŠ” ìŠ¬ë¡œìš° ë¼ì´í”„ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ë„êµ¬ë‹¤',
        }
        test_visual = {
            'concept_title': 'ë””ì§€í„¸ ì •ì›',
            'visual_mood': 'contemplative',
            'brand_alignment': 'ì—¬ë°±ê³¼ ëŠë¦¼ì˜ ë¯¸í•™',
        }

        result = agent.write_content(test_analysis, test_visual)
        print(f"\nâœï¸  ì½˜í…ì¸  ì´ˆì•ˆ:")
        print(f"   í—¤ë“œë¼ì¸: {result.get('headline', 'N/A')}")
        print(f"   ìº¡ì…˜: {result.get('social_caption', 'N/A')}")
        print(f"   ë¸Œëœë“œ ë³´ì´ìŠ¤ ì¶œì²˜: {result.get('brand_voice_source', 'N/A')}")
        print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    else:
        agent.start_watching(interval=args.interval)
