#!/usr/bin/env python3
"""
97layerOS Strategy Analyst (SA) Agent
Phase 6.2: Independent agent with Gemini Flash API

Role:
- Signal analysis and strategic insight extraction
- First responder to incoming signals
- Pattern recognition across signals
- Strategic recommendations

LLM: Gemini 2.5 Flash (Free tier, fast)
Queue: Autonomous task claiming via AgentWatcher
Output: Structured analysis â†’ passed to AD/CE

Author: 97layerOS Technical Director
Updated: 2026-02-16 (google.genai SDK ë§ˆì´ê·¸ë ˆì´ì…˜)
"""

import os
import sys
import json
import time
import re
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime

# Project setup
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from core.system.agent_watcher import AgentWatcher
from core.system.queue_manager import Task

# Using REST API directly - no SDK needed


class StrategyAnalyst:
    """
    Strategy Analyst Agent - Signal Analysis & Strategic Insights

    Capabilities:
    - Analyze incoming signals (text, links, images)
    - Extract strategic themes and patterns
    - Identify action items and opportunities
    - Generate initial insights for other agents
    """

    def __init__(self, agent_id: str = "sa-worker-1", api_key: Optional[str] = None):
        """
        Initialize Strategy Analyst

        Args:
            agent_id: Unique agent instance ID
            api_key: Google API key (or from env GOOGLE_API_KEY)
        """
        self.agent_id = agent_id
        self.agent_type = "SA"

        # Initialize Gemini API (REST API ì§ì ‘ í˜¸ì¶œ)
        self.api_key = api_key or os.getenv('GOOGLE_API_KEY')
        if not self.api_key:
            raise ValueError("GOOGLE_API_KEY not found in environment")

        self._model_name = 'gemini-2.5-flash'
        self._api_url = 'https://generativelanguage.googleapis.com/v1beta/models'

        # SA ì—ì´ì „íŠ¸ ì§€ì¹¨ ë¡œë“œ
        self._persona = self._load_directive()

        print(f"SA: ì¤€ë¹„ë¨. (Key: ...{self.api_key[-4:]})")

    def analyze_signal(self, signal_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analyze incoming signal and extract strategic insights

        Args:
            signal_data: Signal content and metadata
                {
                    'signal_id': str,
                    'content': str,
                    'source': str (telegram, slack, etc.),
                    'timestamp': str,
                    'attachments': list (optional)
                }

        Returns:
            Analysis result with strategic insights
        """
        signal_id = signal_data.get('signal_id', 'unknown')
        content = signal_data.get('content', '')
        source = signal_data.get('source', 'unknown')

        print(f"SA: ì‹ í˜¸ {signal_id} ë¶„ì„ ì‹œì‘. [API: {self._api_url}]")

        # Construct prompt for strategic analysis
        prompt = self._build_analysis_prompt(content, source)

        try:
            # Call Gemini API (REST API ì§ì ‘ í˜¸ì¶œ)
            import requests
            api_url = f"{self._api_url}/{self._model_name}:generateContent"
            headers = {"Content-Type": "application/json"}
            payload = {"contents": [{"parts": [{"text": prompt}]}]}

            response = requests.post(f"{api_url}?key={self.api_key}",
                                    headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            analysis_text = response.json()['candidates'][0]['content']['parts'][0]['text']

            # Parse structured response
            analysis = self._parse_analysis(analysis_text)

            # Add metadata
            analysis.update({
                'signal_id': signal_id,
                'analyzed_by': self.agent_id,
                'analyzed_at': datetime.now().isoformat(),
                'model': self._model_name,
                'source': source
            })

            score = analysis.get('strategic_score', 0)
            category = analysis.get('category', '')
            themes = ', '.join(analysis.get('themes', [])[:3])
            print(f"SA: ì™„ë£Œ. ì ìˆ˜ {score}. ì¹´í…Œê³ ë¦¬: {category}. í…Œë§ˆ: {themes}.")

            # ìê°€ë°œì „: SA ë¶„ì„ ì™„ë£Œ â†’ long_term_memory í”¼ë“œë°±
            try:
                self._feedback_to_memory(analysis, content)
            except Exception as mem_e:
                print(f"âš ï¸  Memory feedback skipped: {mem_e}")

            # ìê°€ë°œì „: SA ë¶„ì„ ì™„ë£Œ â†’ NotebookLM Signal Archive ì €ì¥
            try:
                self._save_to_notebooklm(analysis, content, source)
            except Exception as nlm_e:
                print(f"âš ï¸  NotebookLM skipped: {nlm_e}")

            # Corpus ëˆ„ì : ì‹ í˜¸ â†’ ì§€ì‹ í’€ (êµ°ì§‘ ê¸°ë°˜ ë°œí–‰ì„ ìœ„í•œ ì¶•ì )
            try:
                from core.system.corpus_manager import CorpusManager
                corpus = CorpusManager()
                corpus.add_entry(signal_id, analysis, signal_data)
                print(f"SA: Corpus ëˆ„ì  ì™„ë£Œ â†’ {signal_id}")
            except Exception as corpus_e:
                print(f"âš ï¸  Corpus skipped: {corpus_e}")

            # ì‹ í˜¸ íŒŒì¼ status â†’ analyzed (Orchestrator ì¤‘ë³µ íˆ¬ì… ë°©ì§€)
            try:
                import pathlib
                signal_path = signal_data.get('signal_path') or str(
                    PROJECT_ROOT / 'knowledge' / 'signals' / f"{signal_id}.json"
                )
                sp = pathlib.Path(str(signal_path))
                if sp.exists():
                    sig_json = json.loads(sp.read_text())
                    sig_json['status'] = 'analyzed'
                    sig_json['analyzed_at'] = datetime.now().isoformat()
                    sp.write_text(json.dumps(sig_json, indent=2, ensure_ascii=False))
                    print(f"SA: ì‹ í˜¸ status â†’ analyzed: {signal_id}")
            except Exception as upd_e:
                print(f"âš ï¸  Signal status update skipped: {upd_e}")

            return analysis

        except Exception as e:
            print(f"SA: ë¶„ì„ ì‹¤íŒ¨. {e}")
            return {
                'signal_id': signal_id,
                'error': str(e),
                'status': 'failed'
            }

    def _load_directive(self) -> str:
        """SA.md ì—ì´ì „íŠ¸ ì§€ì¹¨ ë¡œë“œ"""
        persona_path = PROJECT_ROOT / 'directives' / 'agents' / 'SA.md'
        try:
            if persona_path.exists():
                return persona_path.read_text(encoding='utf-8')
        except Exception:
            pass
        return "ëƒ‰ì •í•˜ê²Œ ë¶„ì„í•˜ë¼. í•„ìš”í•œ ê²ƒë§Œ ë§í•´ë¼."

    def _feedback_to_memory(self, analysis: Dict[str, Any], original_content: str):
        """
        SA ë¶„ì„ ì™„ë£Œ í›„ long_term_memory.jsonì— ì¸ì‚¬ì´íŠ¸ ëˆ„ì  â€” ìê°€ë°œì „ ê³ ë¦¬

        themes â†’ concepts ì¹´ìš´íŠ¸ ëˆ„ì 
        key_insights + summary â†’ experiences ì¶”ê°€
        strategic_score 80+ ë§Œ ì €ì¥ (ë…¸ì´ì¦ˆ í•„í„°)
        """
        score = analysis.get('strategic_score', 0)
        if score < 50:
            return  # ë…¸ì´ì¦ˆëŠ” ê¸°ë¡ ì•ˆ í•¨

        lm_path = PROJECT_ROOT / 'knowledge' / 'long_term_memory.json'

        try:
            if lm_path.exists():
                data = json.loads(lm_path.read_text(encoding='utf-8'))
            else:
                data = {
                    'metadata': {'created_at': datetime.now().isoformat(), 'total_entries': 0},
                    'experiences': [],
                    'concepts': {},
                    'error_patterns': []
                }
        except Exception:
            return

        # themes â†’ concepts ì¹´ìš´íŠ¸ (ë¹ˆë„ = ì¤‘ìš”ë„)
        for theme in analysis.get('themes', []):
            theme = theme.strip()
            if theme:
                data['concepts'][theme] = data['concepts'].get(theme, 0) + 1

        # category ë„ conceptsì— ë°˜ì˜
        category = analysis.get('category', '')
        if category and category not in ('noise', 'unknown'):
            data['concepts'][f'SA:{category}'] = data['concepts'].get(f'SA:{category}', 0) + 1

        # experiences: summary + top insight ê¸°ë¡
        insights = analysis.get('key_insights', [])
        insight_preview = insights[0][:80] if insights else ''
        summary = analysis.get('summary', '')[:100]
        combined = f"[SA score:{score}] {summary}" + (f" | {insight_preview}" if insight_preview else '')

        data['experiences'].append({
            'summary': combined[:150],
            'category': 'SAë¶„ì„',
            'timestamp': datetime.now().isoformat()[:16],
            'source': 'sa_agent',
            'score': score
        })

        # ìµœê·¼ 100ê°œ ìœ ì§€
        if len(data['experiences']) > 100:
            data['experiences'] = data['experiences'][-100:]

        data['metadata']['total_entries'] = len(data['experiences'])
        data['metadata']['last_updated'] = datetime.now().isoformat()[:16]

        lm_path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding='utf-8')
        print(f"ğŸ“ Memory updated: score={score}, themes={analysis.get('themes', [])[:3]}")

    def _save_to_notebooklm(self, analysis: Dict[str, Any], content: str, source: str):
        """
        SA ë¶„ì„ ì™„ë£Œ í›„ NotebookLM Signal Archiveì— ì €ì¥.
        score 60+ ë§Œ ì €ì¥ (ë…¸ì´ì¦ˆ ì œì™¸).
        """
        score = analysis.get('strategic_score', 0)
        if score < 60:
            return

        try:
            from core.bridges.notebooklm_bridge import get_bridge, is_available
            if not is_available():
                return

            bridge = get_bridge()
            bridge.add_signal_to_archive({
                'signal_id': analysis.get('signal_id', ''),
                'content': content,
                'source': source,
                'analysis': analysis,
            })
            print(f"ğŸ“š NotebookLM ì €ì¥: score={score}")
        except ImportError:
            pass  # ë¸Œë¦¿ì§€ ì—†ìœ¼ë©´ ì¡°ìš©íˆ ìŠ¤í‚µ

    def _build_analysis_prompt(self, content: str, source: str) -> str:
        """SAì˜ ì‹œê°ìœ¼ë¡œ ì‹ í˜¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        return f"""ë„ˆëŠ” SAì´ë‹¤. 97layer í¬ë£¨ì˜ ì „ëµ ë¶„ì„ê°€.

{self._persona[:600]}

---

ë‹¤ìŒ ì‹ í˜¸ë¥¼ ë¶„ì„í•˜ë¼. 97layerì˜ ë°©í–¥ê³¼ ì–¼ë§ˆë‚˜ ì •ë ¬ë˜ì–´ ìˆëŠ”ì§€ ëƒ‰ì •í•˜ê²Œ íŒë‹¨í•œë‹¤.

**ì‹ í˜¸ ë‚´ìš©:**
{content}

**ì¶œì²˜:** {source}

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:
{{
  "strategic_score": <0-100, 97layer ë°©í–¥ ì •ë ¬ë„ + ì „ëµ ê°€ì¹˜>,
  "category": "<trend|insight|opportunity|question|noise>",
  "themes": ["í…Œë§ˆ1", "í…Œë§ˆ2", "í…Œë§ˆ3"],
  "key_insights": [
    "ì¸ì‚¬ì´íŠ¸ 1 (í•œ ë¬¸ì¥, ì§ì ‘ì ìœ¼ë¡œ)",
    "ì¸ì‚¬ì´íŠ¸ 2",
    "ì¸ì‚¬ì´íŠ¸ 3"
  ],
  "action_items": [
    "êµ¬ì²´ì ì¸ ë‹¤ìŒ í–‰ë™ 1",
    "êµ¬ì²´ì ì¸ ë‹¤ìŒ í–‰ë™ 2"
  ],
  "recommended_agents": ["AD", "CE", "CD"],
  "summary": "í•œ ë¬¸ì¥ ìš”ì•½ â€” í•µì‹¬ë§Œ"
}}

**íŒë‹¨ ê¸°ì¤€:**
- 80+: 97layer ë°©í–¥ê³¼ ì •ë ¬. í–‰ë™í•  ê°€ì¹˜ ìˆìŒ.
- 50-79: íƒìƒ‰í•  ë§Œí•¨. íŒ¨í„´ ì£¼ì‹œ.
- 50 ë¯¸ë§Œ: ë…¸ì´ì¦ˆ. ì•Œê³ ë¦¬ì¦˜ ì¶”ì¢… ë˜ëŠ” ë°©í–¥ ë¶ˆì¼ì¹˜.
- ìŠ¬ë¡œìš°ë¼ì´í”„Â·ë³¸ì§ˆÂ·ì—¬ë°±Â·ì§„ì •ì„± ê´€ë ¨ ì‹ í˜¸ëŠ” ë†’ê²Œ í‰ê°€.
- ë¹ ë¥¸ íŠ¸ë Œë“œÂ·ê³¼ë„í•œ ì¥ì‹Â·ì•Œê³ ë¦¬ì¦˜ ì¶”ì¢… ì‹ í˜¸ëŠ” ë‚®ê²Œ í‰ê°€.

JSONë§Œ ì¶œë ¥. ì„¤ëª… ì—†ì´.
"""

    def _parse_analysis(self, analysis_text: str) -> Dict[str, Any]:
        """Parse Gemini response into structured data"""
        try:
            # Try to extract JSON from response
            # Sometimes Gemini wraps JSON in ```json ... ```
            if '```json' in analysis_text:
                json_start = analysis_text.find('```json') + 7
                json_end = analysis_text.find('```', json_start)
                json_text = analysis_text[json_start:json_end].strip()
            elif '```' in analysis_text:
                json_start = analysis_text.find('```') + 3
                json_end = analysis_text.find('```', json_start)
                json_text = analysis_text[json_start:json_end].strip()
            else:
                json_text = analysis_text.strip()

            analysis = json.loads(json_text)

            # Validate required fields
            required_fields = ['strategic_score', 'category', 'themes', 'key_insights', 'summary']
            for field in required_fields:
                if field not in analysis:
                    analysis[field] = None

            return analysis

        except json.JSONDecodeError as e:
            print(f"âš ï¸  {self.agent_id}: Failed to parse JSON, using fallback")
            return {
                'strategic_score': 50,
                'category': 'insight',
                'themes': ['unknown'],
                'key_insights': [analysis_text[:200]],
                'summary': analysis_text[:100],
                'raw_response': analysis_text,
                'parse_error': str(e)
            }

    def process_task(self, task: Task) -> Dict[str, Any]:
        """
        Process task from queue (callback for AgentWatcher)

        Args:
            task: Task from queue

        Returns:
            Task result
        """
        task_type = task.task_type
        payload = task.payload

        print(f"ğŸ“‹ {self.agent_id}: Processing task {task.task_id} ({task_type})")

        if task_type == 'analyze_signal':
            # Analyze signal
            result = self.analyze_signal(payload)
            return {
                'status': 'completed',
                'task_id': task.task_id,
                'result': result
            }

        elif task_type == 'batch_analyze':
            # Batch analysis (multiple signals)
            signals = payload.get('signals', [])
            results = []
            for signal in signals:
                analysis = self.analyze_signal(signal)
                results.append(analysis)

            return {
                'status': 'completed',
                'task_id': task.task_id,
                'results': results,
                'count': len(results)
            }

        else:
            return {
                'status': 'failed',
                'error': f"Unknown task type: {task_type}"
            }

    def start_watching(self, interval: int = 5):
        """
        Start autonomous queue watching

        Args:
            interval: Poll interval in seconds
        """
        watcher = AgentWatcher(
            agent_type=self.agent_type,
            agent_id=self.agent_id
        )

        print(f"SA: í ê°ì‹œ ì‹œì‘.")

        # Start watching (blocking)
        watcher.watch(
            callback=self.process_task,
            interval=interval
        )


# ================== Standalone Execution ==================

if __name__ == '__main__':
    import argparse
    from core.system.env_validator import validate_env
    validate_env("sa_agent")

    parser = argparse.ArgumentParser(description='97layerOS Strategy Analyst Agent')
    parser.add_argument('--agent-id', default='sa-worker-1', help='Agent instance ID')
    parser.add_argument('--interval', type=int, default=5, help='Queue poll interval (seconds)')
    parser.add_argument('--test', action='store_true', help='Run test mode (single analysis)')

    args = parser.parse_args()

    # Initialize agent
    try:
        agent = StrategyAnalyst(agent_id=args.agent_id)
    except ValueError as e:
        print(f"âŒ Initialization failed: {e}")
        print("ğŸ’¡ Set GOOGLE_API_KEY environment variable")
        sys.exit(1)

    if args.test:
        # Test mode: Single analysis
        print("\nğŸ§ª Test Mode: Single Signal Analysis")
        print("=" * 50)

        test_signal = {
            'signal_id': 'test_001',
            'content': """
            I've been thinking about how AI tools are changing creative work.
            Instead of replacing creativity, they're removing the boring parts -
            research, formatting, repetitive tasks. This frees us to focus on
            what matters: ideas, connections, meaningful work. Maybe this aligns
            with slow living philosophy?
            """,
            'source': 'telegram',
            'timestamp': datetime.now().isoformat()
        }

        result = agent.analyze_signal(test_signal)

        print(f"\nğŸ“Š Analysis Result:")
        print(f"   Strategic Score: {result.get('strategic_score', 'N/A')}")
        print(f"   Category: {result.get('category', 'N/A')}")
        print(f"   Themes: {', '.join(result.get('themes', []))}")
        print(f"   Summary: {result.get('summary', 'N/A')}")
        print(f"\n   Key Insights:")
        for insight in result.get('key_insights', []):
            print(f"   - {insight}")

        print("\nâœ… Test complete!")

    else:
        # Production mode: Autonomous queue watching
        print("\nğŸš€ Production Mode: Autonomous Queue Watching")
        print("=" * 50)
        agent.start_watching(interval=args.interval)
