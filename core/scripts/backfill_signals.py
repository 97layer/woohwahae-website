#!/usr/bin/env python3
"""
Signal Backfill â€” ê¸°ì¡´ signal JSONì— ëˆ„ë½ í•„ë“œ ì±„ìš°ê¸°

ìŠ¤í‚¤ë§ˆ v2.0 ê¸°ì¤€ìœ¼ë¡œ:
- signal_id ì—†ìœ¼ë©´ íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ
- content ì—†ìœ¼ë©´ transcript/analysis.descriptionì—ì„œ ì¶”ì¶œ
- from_user ì—†ìœ¼ë©´ "97layer" ê¸°ë³¸ê°’
- source_channel ì—†ìœ¼ë©´ "manual" ê¸°ë³¸ê°’
- ìµœìƒìœ„ analysis/video_id/source â†’ metadata ì•ˆìœ¼ë¡œ ì •ë¦¬
- analyzed_at ì—†ê³  status=analyzedë©´ íŒŒì¼ mtime ì‚¬ìš©

dry-run ê¸°ë³¸. --applyë¡œ ì‹¤ì œ ì“°ê¸°.
"""

import json
import logging
import sys
from datetime import datetime
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
SIGNALS_DIR = PROJECT_ROOT / "knowledge" / "signals"

logging.basicConfig(level=logging.INFO, format="%(message)s")
logger = logging.getLogger(__name__)


def _extract_signal_id(filepath: Path, data: dict) -> str:
    """íŒŒì¼ëª…ì—ì„œ signal_id ì¶”ì¶œ"""
    stem = filepath.stem  # e.g. "youtube_7HBhL7lltpU_20260217_141746"
    sig_type = data.get("type", "")

    if sig_type == "youtube_video":
        # youtube_{videoId}_{YYYYMMDD}_{HHMMSS} â†’ signal_id í˜•íƒœë¡œ
        parts = stem.split("_")
        if len(parts) >= 4:
            date_part = parts[-2]
            time_part = parts[-1]
            return "youtube_video_%s_%s" % (date_part, time_part)

    if sig_type == "image":
        parts = stem.split("_")
        if len(parts) >= 3:
            date_part = parts[-2]
            time_part = parts[-1]
            return "image_%s_%s" % (date_part, time_part)

    # text, url_content ë“±ì€ ë³´í†µ ì´ë¯¸ signal_idê°€ ìˆìŒ
    return stem


def _extract_content(data: dict) -> str:
    """content í•„ë“œ ì¶”ì¶œ â€” transcript, analysis.description ë“±ì—ì„œ"""
    if data.get("content"):
        return data["content"]

    # youtube: transcriptì—ì„œ
    transcript = data.get("transcript", "")
    if transcript:
        return transcript[:500]

    # image: analysis.descriptionì—ì„œ
    analysis = data.get("analysis", {})
    if isinstance(analysis, dict):
        desc = analysis.get("description", "")
        if desc:
            return desc[:500]
        caption = analysis.get("caption", "")
        if caption:
            return caption

    return ""


def backfill_signal(filepath: Path, apply: bool = False) -> list:
    """ë‹¨ì¼ signal JSON ë°±í•„. ë³€ê²½ì‚¬í•­ ëª©ë¡ ë°˜í™˜."""
    changes = []

    try:
        raw = filepath.read_text(encoding="utf-8")
        data = json.loads(raw)
    except Exception as exc:
        return [("ERROR", str(exc))]

    # signal_id
    if not data.get("signal_id"):
        sid = _extract_signal_id(filepath, data)
        data["signal_id"] = sid
        changes.append(("ADD", "signal_id", sid))

    # content
    if not data.get("content"):
        content = _extract_content(data)
        if content:
            data["content"] = content
            changes.append(("ADD", "content", content[:60] + "..."))

    # from_user
    if not data.get("from_user"):
        data["from_user"] = "97layer"
        changes.append(("ADD", "from_user", "97layer"))

    # source_channel
    if not data.get("source_channel"):
        data["source_channel"] = "manual"
        changes.append(("ADD", "source_channel", "manual"))

    # analyzed_at (status=analyzedì¸ë° ì—†ëŠ” ê²½ìš°)
    if data.get("status") == "analyzed" and not data.get("analyzed_at"):
        mtime = datetime.fromtimestamp(filepath.stat().st_mtime).isoformat()
        data["analyzed_at"] = mtime
        changes.append(("ADD", "analyzed_at", mtime))

    # metadata ì •ë¦¬: ìµœìƒìœ„ video_id, source, analysis â†’ metadataë¡œ
    metadata = data.get("metadata", {})
    if not isinstance(metadata, dict):
        metadata = {}

    if "video_id" in data and "video_id" not in metadata:
        metadata["video_id"] = data.pop("video_id")
        changes.append(("MOVE", "video_id â†’ metadata.video_id"))

    if "source" in data and data["type"] != "image":
        url = data.pop("source")
        if url and "source_url" not in metadata:
            metadata["source_url"] = url
            changes.append(("MOVE", "source â†’ metadata.source_url"))

    if "transcript" in data:
        preview = data.pop("transcript")[:2000]
        if "transcript_preview" not in metadata:
            metadata["transcript_preview"] = preview
            changes.append(("MOVE", "transcript â†’ metadata.transcript_preview"))

    if "full_transcript_length" in data:
        length = data.pop("full_transcript_length")
        metadata["transcript_length"] = length
        changes.append(("MOVE", "full_transcript_length â†’ metadata.transcript_length"))

    # image: source â†’ metadata.image_path
    if data.get("type") == "image" and "source" in data:
        src = data.pop("source")
        if "image_path" not in metadata:
            metadata["image_path"] = src
            changes.append(("MOVE", "source â†’ metadata.image_path"))

    if "saved_image" in data:
        saved = data.pop("saved_image")
        if "image_path" not in metadata:
            metadata["image_path"] = saved
        changes.append(("MOVE", "saved_image â†’ metadata.image_path"))

    # ìµœìƒìœ„ analysis â†’ metadata.analysis
    if "analysis" in data and "analysis" not in metadata:
        metadata["analysis"] = data.pop("analysis")
        changes.append(("MOVE", "analysis â†’ metadata.analysis"))
    elif "analysis" in data and "analysis" in metadata:
        data.pop("analysis")
        changes.append(("DROP", "duplicate top-level analysis"))

    if metadata:
        data["metadata"] = metadata

    # ì“°ê¸°
    if changes and apply:
        filepath.write_text(
            json.dumps(data, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )

    return changes


def main():
    apply = "--apply" in sys.argv

    if not SIGNALS_DIR.exists():
        logger.error("signals/ ë””ë ‰í† ë¦¬ ì—†ìŒ")
        return

    total_files = 0
    total_changes = 0

    for sf in sorted(SIGNALS_DIR.glob("**/*.json")):
        changes = backfill_signal(sf, apply=apply)
        if changes:
            total_files += 1
            total_changes += len(changes)
            rel = sf.relative_to(PROJECT_ROOT)
            logger.info("\nğŸ“„ %s", rel)
            for c in changes:
                if len(c) == 3:
                    logger.info("  %s %s = %s", c[0], c[1], c[2])
                else:
                    logger.info("  %s %s", c[0], c[1])

    mode = "APPLIED" if apply else "DRY-RUN"
    logger.info("\n--- %s ---", mode)
    logger.info("íŒŒì¼: %d / ë³€ê²½: %d", total_files, total_changes)
    if not apply and total_changes > 0:
        logger.info("ì‹¤ì œ ì ìš©: python3 core/scripts/backfill_signals.py --apply")


if __name__ == "__main__":
    main()
