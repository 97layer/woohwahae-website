#!/usr/bin/env python3
"""
97layerOS Cortex Edge
The Central Intelligence Gateway for systemic coordination.

Features:
- Unified Engine: Single interface for text, vision, and RAG.
- Contextual Awareness: Integrated Identity + Memory + Signals.
- Multi-Source RAG: High-performance local search + Cloud fallback.
- API Standardization: Uniform request/response for Telegram and Web.
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime

# Import Engines
from core.system.gemini_engine import get_gemini_engine
from core.system.conversation_engine import ConversationEngine
from core.system.queue_manager import QueueManager

logger = logging.getLogger(__name__)
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent

class CortexEdge:
    """
    97layerOSì˜ ì¤‘ì•™ ì‚¬ê³  ì—”ì§„.
    ì‹œìŠ¤í…œ ì „ì²´ì˜ ì¸í…”ë¦¬ì „ìŠ¤ë¥¼ ì¡°ì •í•˜ê³  í†µí•©ëœ ë§¥ë½ì„ ì œê³µí•¨.
    """
    def __init__(self):
        self.gemini = get_gemini_engine()
        self.conv_engine = ConversationEngine()  # Existing logic for memory/RAG
        self.queue = QueueManager()
        
        self.knowledge_dir = PROJECT_ROOT / 'knowledge'
        self.signals_dir = self.knowledge_dir / 'signals'
        
        logger.info("ðŸ§  Cortex Edge Engine Active")

    def query(self, user_id: str, text: str, mode: str = "chat") -> Dict[str, Any]:
        """
        í†µí•© ì¿¼ë¦¬ ì²˜ë¦¬ê¸°.
        
        Args:
            user_id: ìš”ì²­ìž ì‹ë³„ìž
            text: ìž…ë ¥ ë©”ì‹œì§€
            mode: 'chat', 'analyze', 'search' ë“±
            
        Returns:
            í†µí•© ì‘ë‹µ ê°ì²´
        """
        start_time = datetime.now()
        
        # 1. ì˜ë„ ë¶„ì„ ë° ë§¥ë½ êµ¬ì„± (ConversationEngine ë¡œì§ í™œìš©)
        response_text = self.conv_engine.chat(user_id, text)
        
        # 2. ìž¥ê¸° ê¸°ì–µ ì—…ë°ì´íŠ¸ (Graph Extraction) - ë¹„ë™ê¸° ì‹œë®¬ë ˆì´ì…˜
        try:
            self._update_long_term_memory(text, response_text)
        except Exception as e:
            logger.error(f"Memory update error: {e}")
        
        # 2. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë° ë©”íƒ€ë°ì´í„° ì¶”ê°€
        latency = (datetime.now() - start_time).total_seconds()
        
        return {
            "user_id": user_id,
            "response": response_text,
            "latency": f"{latency:.2f}s",
            "timestamp": datetime.now().isoformat(),
            "engine": "Cortex-V1"
        }

    def inject_signal(self, text: str, source: str = "web") -> Dict[str, Any]:
        """
        ì‹ í˜¸(ì¸ì‚¬ì´íŠ¸) ì£¼ìž… ë° ë¹„ë™ê¸° ë¶„ì„ íŠ¸ë¦¬ê±°.
        """
        self.signals_dir.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        signal_id = f"{source}_{timestamp}"
        
        signal_data = {
            'signal_id': signal_id,
            'type': 'text_insight',
            'content': text,
            'captured_at': datetime.now().isoformat(),
            'from_user': source,
            'status': 'captured'
        }
        
        # íŒŒì¼ ì €ìž¥
        signal_path = self.signals_dir / f"{signal_id}.json"
        with open(signal_path, 'w', encoding='utf-8') as f:
            json.dump(signal_data, f, ensure_ascii=False, indent=2)
            
        # SA ë¶„ì„ íƒœìŠ¤í¬ ìƒì„± (í ë§¤ë‹ˆì € ì—°ë™)
        task_id = self.queue.create_task(
            agent_type='SA',
            task_type='analyze',
            payload={
                'signal_id': signal_id,
                'content': text,
                'source': f'cortex_{source}'
            }
        )
        
        return {
            "success": True,
            "signal_id": signal_id,
            "task_id": task_id
        }

    def _update_long_term_memory(self, user_message: str, assistant_answer: str):
        """
        ìž¥ê¸° ê¸°ì–µì„ ì—…ë°ì´íŠ¸í•˜ê³  ê°œë… ë° ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ì—¬ ì˜¨í†¨ë¡œì§€ì— ì €ìž¥.
        """
        memory_path = self.knowledge_dir / 'long_term_memory.json'
        data = {"concepts": {}, "experiences": [], "metadata": {}}

        if memory_path.exists():
            try:
                with open(memory_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
            except json.JSONDecodeError:
                logger.warning("long_term_memory.json is corrupted, starting fresh.")
                data = {"concepts": {}, "experiences": [], "metadata": {}}

        # Add new experience
        data['experiences'].append({
            "user": user_message,
            "assistant": assistant_answer,
            "timestamp": datetime.now().isoformat()
        })
        
        # Geminië¡œ ê°œë… ë° ê´€ê³„ ì¶”ì¶œ (Graph Extraction)
        extract_prompt = f"""ë‹¤ìŒ ëŒ€í™”ì—ì„œ 97layer ê°œì¸ì˜ í•µì‹¬ ê°œë…(Nodes)ê³¼ ê°œë… ê°„ì˜ ê´€ê³„(Edges)ë¥¼ ì¶”ì¶œí•˜ë¼.

ì‚¬ìš©ìž: {user_message[:300]}
ë¹„ì„œ: {assistant_answer[:300]}

JSONìœ¼ë¡œë§Œ ì‘ë‹µ:
{{
  "concepts": ["ê°œë…1", "ê°œë…2"],
  "relations": [
    {{"source": "ê°œë…1", "target": "ê°œë…2", "relation": "ì—°ê²°ì–´", "strength": 0.5}}
  ],
  "summary": "í•œ ë¬¸ìž¥ ìš”ì•½",
  "category": "ë¸Œëžœë“œ/ê°œì¸/ê¸°ìˆ /ë¹„ì¦ˆë‹ˆìŠ¤/ë¼ì´í”„ìŠ¤íƒ€ì¼ ì¤‘ í•˜ë‚˜"
}}"""

        try:
            resp = self.gemini.generate_text(extract_prompt) # Use GeminiEngine
            import re
            json_match = re.search(r'\{.*\}', resp, re.DOTALL)
            if not json_match:
                return
            extracted = json.loads(json_match.group())
        except Exception as e:
            logger.error(f"Failed to extract knowledge: {e}")
            return

        # Prepare Ontology section
        if 'ontology' not in data:
            data['ontology'] = {"nodes": [], "edges": []}

        # concepts ë° nodes ì—…ë°ì´íŠ¸
        for concept in extracted.get('concepts', []):
            concept = concept.strip()
            if concept:
                # Flat count for backward compatibility
                data['concepts'][concept] = data['concepts'].get(concept, 0) + 1
                
                # Graph Nodes
                node_exists = False
                for node in data['ontology']['nodes']:
                    if node['id'] == concept:
                        node['weight'] = node.get('weight', 0) + 1
                        node_exists = True
                        break
                if not node_exists:
                    data['ontology']['nodes'].append({
                        "id": concept,
                        "type": extracted.get('category', 'unknown'),
                        "weight": 1
                    })

        # Graph Edges ì—…ë°ì´íŠ¸
        for rel in extracted.get('relations', []):
            source = rel.get('source')
            target = rel.get('target')
            if source and target:
                edge_exists = False
                for edge in data['ontology']['edges']:
                    if edge['source'] == source and edge['target'] == target:
                        edge['strength'] = min(1.0, edge.get('strength', 0.5) + 0.1)
                        edge_exists = True
                        break
                if not edge_exists:
                    data['ontology']['edges'].append({
                        "source": source,
                        "target": target,
                        "relation": rel.get('relation', 'connected'),
                        "strength": rel.get('strength', 0.5)
                    })

        data['metadata']['last_updated'] = datetime.now().isoformat()

        with open(memory_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def get_system_status(self) -> Dict[str, Any]:
        """
        ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½ (Cockpitìš©)
        """
        memory_path = self.knowledge_dir / 'long_term_memory.json'
        memory = {}
        if memory_path.exists():
            try:
                memory = json.loads(memory_path.read_text(encoding='utf-8'))
            except:
                pass
        
        recent_signals = sorted(
            self.signals_dir.glob('*.json'),
            key=lambda p: p.stat().st_mtime,
            reverse=True
        )[:5]
        
        return {
            "intelligence": {
                "concepts": len(memory.get('concepts', {})),
                "experiences": len(memory.get('experiences', [])),
                "last_update": memory.get('metadata', {}).get('last_updated')
            },
            "signals": {
                "recent": [f.name for f in recent_signals]
            }
        }

# Singleton
_ctx_instance = None

def get_cortex() -> CortexEdge:
    global _ctx_instance
    if _ctx_instance is None:
        _ctx_instance = CortexEdge()
    return _ctx_instance
