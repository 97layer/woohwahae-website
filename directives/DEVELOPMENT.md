# ğŸ”§ DEVELOPMENT - í†µí•© ê°œë°œ ì§€ì¹¨ v3.0

> **í†µí•©**: token_optimization_protocol + system_sop + infrastructure_sentinel + directive_lifecycle + skills_integration + data_asset_management + 97layerOS_Optimization_Directive + system_handshake + agent_instructions
> **ë²„ì „**: 3.0
> **ê°±ì‹ **: 2026-02-15
> **ì² í•™**: "ì´ íŒŒì¼ì€ ê³„ì† ì„±ì¥í•œë‹¤. íŒŒí¸í™”í•˜ì§€ ë§ê³  ì—¬ê¸°ì— ì¶”ê°€í•˜ë¼."

---

## ğŸ¯ Development Philosophy

### Core Principle: Token-First Development
```python
# ëª¨ë“  ê°œë°œì˜ ì‹œì‘
def before_any_development():
    """í† í°ì€ ëˆì´ë‹¤. ë‚­ë¹„ëŠ” ì£„ë‹¤."""

    # Rule 1: Query Before Read
    search_first()

    # Rule 2: Cache Everything
    use_cache()

    # Rule 3: Batch Process
    batch_not_loop()

    return "60-80% token saved"
```

---

## ğŸ’° Token Optimization Protocol

### Layer 1: Query Strategy

#### âŒ BAD Pattern (20,000+ tokens)
```python
# ì „ì²´ íŒŒì¼ ì½ê¸°
content = Read("large_module.py")
# ì „ì²´ ê²€ìƒ‰
all_results = search_everything()
# ë°˜ë³µ í˜¸ì¶œ
for item in items:
    ai_call(item)
```

#### âœ… GOOD Pattern (1,500 tokens)
```python
# 1. Globìœ¼ë¡œ í›„ë³´ ì°¾ê¸°
files = Glob("**/*target*.py")

# 2. Grepìœ¼ë¡œ ì •í™•í•œ ìœ„ì¹˜
matches = Grep("specific_function", files[0])

# 3. Read with offset/limit
content = Read(file, offset=100, limit=20)

# 4. Batch ì²˜ë¦¬
results = ai_batch_call(items)
```

### Layer 2: Caching System

#### Implementation
```python
from functools import lru_cache
from execution.system.token_optimizer import cache_result

@cache_result(ttl_hours=24)
def expensive_operation(prompt):
    """24ì‹œê°„ ìºì‹œ - ê°™ì€ ì§ˆë¬¸ ë°˜ë³µ ë°©ì§€"""
    return ai_engine.generate(prompt)

@lru_cache(maxsize=100)
def frequent_lookup(key):
    """ë©”ëª¨ë¦¬ ìºì‹œ - ìì£¼ ì“°ëŠ” ë°ì´í„°"""
    return database.query(key)
```

#### Cache Strategy
```yaml
Cache Levels:
  L1_Memory: 100 items, TTL 1 hour
  L2_Disk: 1000 items, TTL 24 hours
  L3_Archive: Unlimited, TTL 7 days

Cache Keys:
  Pattern: {function}_{hash(params)}_{date}
  Example: generate_content_a3f4b2_20260215
```

### Layer 3: Batch Processing

```python
# âŒ Sequential (slow, expensive)
for i in range(100):
    result = api.call(data[i])

# âœ… Batch (fast, cheap)
results = api.batch_call(data[:100])

# âœ… Async Parallel (fastest)
async def parallel_process():
    tasks = [api.async_call(d) for d in data]
    return await asyncio.gather(*tasks)
```

---

## ğŸ—ï¸ System Architecture

### 3-Layer Design
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Layer 1: Directives         â”‚  â† ì§€ì¹¨ (What)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       Layer 2: Orchestration        â”‚  â† ê²°ì • (How)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         Layer 3: Execution          â”‚  â† ì‹¤í–‰ (Do)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### File Organization
```
97layerOS/
â”œâ”€â”€ directives/          # 5 core files only
â”‚   â”œâ”€â”€ CORE.md
â”‚   â”œâ”€â”€ IDENTITY.md
â”‚   â”œâ”€â”€ OPERATIONS.md
â”‚   â”œâ”€â”€ PUBLISHING.md
â”‚   â””â”€â”€ DEVELOPMENT.md   # This file
â”œâ”€â”€ execution/
â”‚   â”œâ”€â”€ system/          # Core systems
â”‚   â”œâ”€â”€ api/            # API servers
â”‚   â”œâ”€â”€ ops/            # Operations
â”‚   â”œâ”€â”€ plans/          # PLAN-XXX.md (incremental)
â”‚   â””â”€â”€ utils/          # Utilities
â”œâ”€â”€ knowledge/
â”‚   â”œâ”€â”€ system/         # Single source configs
â”‚   â”œâ”€â”€ magazines/      # Date-based outputs
â”‚   â””â”€â”€ archive/        # Historical records
â””â”€â”€ libs/               # Shared libraries
```

---

## ğŸ”„ Directive Lifecycle

### Version Control Philosophy
```python
class DirectiveManagement:
    """ì§€ì‹œì„œëŠ” ì„±ì¥í•œë‹¤, íŒŒí¸í™”í•˜ì§€ ì•ŠëŠ”ë‹¤"""

    def update_directive(self, file_path, new_content):
        # 1. ë°±ì—…ì€ Gitì´ ë‹´ë‹¹
        git.add(file_path)
        git.commit(f"Before update: {reason}")

        # 2. ë®ì–´ì“°ê¸°ë¡œ ì—…ë°ì´íŠ¸
        file.write(new_content)  # Overwrite

        # 3. ìƒˆ ë²„ì „ ì»¤ë°‹
        git.add(file_path)
        git.commit(f"Updated v{version}: {changes}")

        # 4. íŒŒì¼ëª…ì€ ê·¸ëŒ€ë¡œ
        return file_path  # ê°™ì€ ì´ë¦„ ìœ ì§€
```

### Growth Pattern
```markdown
## Section Name
(Initial content from v1.0)

### Added in v1.1
(New insights)

### Enhanced in v1.2
(Improvements)

### Refined in v2.0
(Major update)
```

---

## ğŸ› ï¸ Infrastructure Management

### System Health Monitoring
```python
class SystemGuardian:
    def __init__(self):
        self.checks = {
            "disk_space": lambda: check_disk() > 1_000_000_000,  # 1GB
            "memory": lambda: check_memory() > 500_000_000,      # 500MB
            "api_keys": lambda: validate_env_vars(),
            "git_clean": lambda: is_git_clean(),
            "services": lambda: check_services_running()
        }

    def health_check(self):
        for name, check in self.checks.items():
            if not check():
                self.auto_fix(name)
```

### Service Management
```bash
# Core Services
97layer-telegram.service    # Telegram bot
97layer-dashboard.service   # Web dashboard
97layer-api.service        # API server
97layer-shadow.service     # Shadow logic

# Management Commands
systemctl status 97layer-*
systemctl restart 97layer-telegram
journalctl -u 97layer-* -f
```

### Backup Strategy
```python
BACKUP_SCHEDULE = {
    "hourly": ["task_board.json"],           # Critical
    "daily": ["knowledge/system/*"],         # System state
    "weekly": ["knowledge/", "directives/"], # Full backup
    "monthly": ["*"]                         # Complete
}

def backup(schedule_type):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    for path in BACKUP_SCHEDULE[schedule_type]:
        backup_path = f".backups/{schedule_type}/{timestamp}/"
        copy(path, backup_path)
```

---

## ğŸ”Œ Skills Integration

### Skill Architecture
```python
class Skill:
    """ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ëŠ¥ë ¥ ë‹¨ìœ„"""

    def __init__(self, name):
        self.name = name
        self.path = f"libs/skills/{name}/"
        self.config = load_config(f"{self.path}/SKILL.md")

    def execute(self, params):
        # 1. Validate input
        self.validate(params)

        # 2. Run skill logic
        result = self.run(params)

        # 3. Cache result
        cache.set(self.cache_key(params), result)

        return result
```

### Available Skills
```yaml
Core Skills:
  signal_capture:     # ì‹ í˜¸ ìˆ˜ì§‘
  data_curation:     # ë°ì´í„° ì •ì œ
  content_creation:  # ì½˜í…ì¸  ìƒì„±
  visual_selection:  # ì´ë¯¸ì§€ ì„ íƒ
  publish_check:     # í¼ë¸”ë¦¬ì‹± ê²€ì¦

Utility Skills:
  instagram_publisher:  # ì¸ìŠ¤íƒ€ ë°œí–‰
  telegram_responder:  # í…”ë ˆê·¸ë¨ ì‘ë‹µ
  backup_manager:      # ë°±ì—… ê´€ë¦¬
  token_optimizer:     # í† í° ìµœì í™”
```

---

## ğŸ“Š Data Asset Management

### Asset Types
```python
ASSET_TYPES = {
    "raw_signals": {
        "path": "knowledge/raw_signals/",
        "format": "rs-{id}_{source}.md",
        "retention": "30 days"
    },
    "patterns": {
        "path": "knowledge/patterns/",
        "format": "pattern_{date}.md",
        "retention": "90 days"
    },
    "content": {
        "path": "knowledge/content/",
        "format": "vol_{n}_{title}.md",
        "retention": "permanent"
    },
    "magazines": {
        "path": "knowledge/magazines/",
        "format": "{date}_{title}.md",
        "retention": "permanent"
    }
}
```

### Asset Lifecycle
```python
def asset_lifecycle(asset):
    # 1. Create
    asset_id = create_asset(asset)

    # 2. Process
    process_asset(asset_id)

    # 3. Archive (after retention)
    if age(asset) > retention_period:
        archive_asset(asset)

    # 4. Purge (if needed)
    if should_purge(asset):
        purge_asset(asset)
```

---

## ğŸ” Security & Credentials

### Environment Variables
```bash
# .env file structure
TELEGRAM_BOT_TOKEN=xxx
GEMINI_API_KEY=xxx
CLAUDE_API_KEY=xxx
OPENAI_API_KEY=xxx
GOOGLE_CREDENTIALS_PATH=credentials.json
```

### Credential Management
```python
class CredentialManager:
    def __init__(self):
        self.load_env()
        self.validate_all()

    def get(self, key):
        value = os.getenv(key)
        if not value:
            raise CredentialError(f"Missing: {key}")
        return value

    def rotate(self, key):
        # Automatic rotation for security
        new_value = generate_new_token()
        update_env(key, new_value)
        reload_services()
```

---

## ğŸš€ Deployment Protocol

### Local Development
```bash
# Setup
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run
python execution/unified_system.py --dev
```

### Production Deployment
```bash
# Pre-deployment checks
python execution/system/quality_gate.py pre

# Deploy
git push origin main
ssh production "cd 97layerOS && git pull && systemctl restart 97layer-*"

# Post-deployment validation
python execution/system/quality_gate.py post production
```

### Rollback Procedure
```python
def emergency_rollback():
    # 1. Stop services
    stop_all_services()

    # 2. Restore backup
    restore_latest_backup()

    # 3. Restart services
    start_all_services()

    # 4. Validate
    run_health_checks()
```

---

## ğŸ§ª Testing Strategy

### Test Levels
```python
# Unit Tests
def test_individual_functions():
    pytest tests/unit/

# Integration Tests
def test_component_interaction():
    pytest tests/integration/

# System Tests
def test_end_to_end():
    pytest tests/e2e/

# Smoke Tests (after deployment)
def smoke_test():
    assert api.health() == "ok"
    assert telegram.ping() == "pong"
    assert dashboard.status() == "running"
```

---

## ğŸ“ˆ Performance Optimization

### Optimization Targets
```yaml
Response Time:
  p50: < 100ms
  p95: < 500ms
  p99: < 1000ms

Resource Usage:
  CPU: < 50% average
  Memory: < 2GB
  Disk I/O: < 100 MB/s

Token Efficiency:
  Reduction: 60-80%
  Cache Hit: > 70%
  Batch Rate: > 50%
```

### Profiling Tools
```python
# Performance profiling
from cProfile import Profile
from memory_profiler import profile

@profile
def memory_intensive_function():
    # Memory usage tracked
    pass

with Profile() as pr:
    cpu_intensive_function()
    pr.print_stats()
```

---

## ğŸ”„ Continuous Improvement

### Self-Annealing Process
```python
while True:
    try:
        execute()
    except Exception as e:
        # 1. Capture error
        error_id = log_error(e)

        # 2. Analyze root cause
        cause = analyze_error(error_id)

        # 3. Fix automatically if possible
        if can_auto_fix(cause):
            apply_fix(cause)

        # 4. Update this document
        update_development_md(lesson_learned)

        # 5. Retry
        continue
```

---

## ğŸ“š Version History

- **v3.0** (2026-02-15): ëŒ€í†µí•© - 9ê°œ íŒŒì¼ â†’ 1ê°œ
  - token_optimization_protocol.md
  - system_sop.md
  - infrastructure_sentinel.md
  - directive_lifecycle.md
  - skills_integration.md
  - data_asset_management.md
  - 97layerOS_Optimization_Directive.md
  - system_handshake.md
  - agent_instructions.md

- **v2.0** (2026-02-01): í† í° ìµœì í™” ì¶”ê°€
- **v1.0** (2026-01-15): ì´ˆê¸° ê°œë°œ ì§€ì¹¨

---

## ğŸŒ± Future Growth Areas

ì´ ì„¹ì…˜ì— ìƒˆë¡œìš´ ê°œë°œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ê°€í•˜ì„¸ìš”:
- [ ] AI Model Management
- [ ] Multi-cloud Strategy
- [ ] Edge Computing Integration
- [ ] Real-time Processing Pipeline

---

> "íŒŒí¸í™”ëŠ” í˜¼ëˆì´ë‹¤. í†µí•©ì€ í˜ì´ë‹¤. ë²„ì „ì„ ì˜¬ë¦¬ë©° ì„±ì¥í•˜ë¼." â€” 97layerOS