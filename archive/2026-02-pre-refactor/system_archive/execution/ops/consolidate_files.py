#!/usr/bin/env python3
"""
ğŸ¯ 97layerOS íŒŒì¼ í†µí•© ìŠ¤í¬ë¦½íŠ¸
281ê°œ MD íŒŒì¼ â†’ 50ê°œ ì´í•˜ë¡œ í†µí•©
"""

import os
import glob
from pathlib import Path
from datetime import datetime
import re

class FileConsolidator:
    def __init__(self):
        self.base_path = Path("/Users/97layer/97layerOS")
        self.signals_path = self.base_path / "knowledge/signals"
        self.content_path = self.base_path / "knowledge/content"
        self.consolidated_count = 0
        self.deleted_count = 0

    def consolidate_telegram_by_date(self):
        """Telegram ëŒ€í™”ë¥¼ ë‚ ì§œë³„ë¡œ í†µí•©"""
        print("\nğŸ“± Telegram ëŒ€í™” í†µí•© ì‹œì‘...")

        # ë‚ ì§œë³„ ê·¸ë£¹í™”
        date_groups = {
            "20260213": [],
            "20260214": [],
            "20260215": []
        }

        telegram_files = glob.glob(str(self.signals_path / "*telegram*.md"))

        for file in telegram_files:
            content = Path(file).read_text(encoding='utf-8')
            filename = os.path.basename(file)

            # ë‚ ì§œ ì¶”ì¶œ
            for date in date_groups.keys():
                if date in filename:
                    date_groups[date].append({
                        'file': filename,
                        'content': content,
                        'timestamp': self.extract_timestamp(filename)
                    })
                    break

        # ë‚ ì§œë³„ í†µí•© íŒŒì¼ ìƒì„±
        for date, files in date_groups.items():
            if not files:
                continue

            # ì‹œê°„ìˆœ ì •ë ¬
            files.sort(key=lambda x: x['timestamp'])

            # í†µí•© íŒŒì¼ ìƒì„±
            consolidated_file = self.signals_path / f"telegram_conversations_{date}.md"

            with open(consolidated_file, 'w', encoding='utf-8') as f:
                f.write(f"# Telegram Conversations - {date}\n\n")
                f.write(f"**í†µí•©ì¼**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
                f.write(f"**ì›ë³¸ íŒŒì¼ ìˆ˜**: {len(files)}ê°œ\n\n")
                f.write("---\n\n")

                for idx, item in enumerate(files, 1):
                    f.write(f"## {idx}. {item['timestamp']} (ì›ë³¸: {item['file']})\n\n")
                    f.write(item['content'])
                    f.write("\n\n---\n\n")

            # ì›ë³¸ íŒŒì¼ ì‚­ì œ
            for item in files:
                os.remove(self.signals_path / item['file'])
                self.deleted_count += 1

            print(f"âœ… {date}: {len(files)}ê°œ íŒŒì¼ â†’ 1ê°œë¡œ í†µí•©")
            self.consolidated_count += 1

    def consolidate_council_logs(self):
        """Council ë¡œê·¸ë¥¼ ì£¼ì œë³„ë¡œ í†µí•©"""
        print("\nğŸ›ï¸ Council ë¡œê·¸ í†µí•© ì‹œì‘...")

        # council_log í´ë” ì°¾ê¸°
        council_files = []
        if (self.content_path / "council_log").exists():
            council_files = glob.glob(str(self.content_path / "council_log" / "*.md"))

        if council_files:
            # logs í´ë” ìƒì„±
            logs_path = self.content_path / "logs"
            logs_path.mkdir(exist_ok=True)

            # ë‚ ì§œë³„ ê·¸ë£¹í™”
            date_groups = {}
            for file in council_files:
                content = Path(file).read_text(encoding='utf-8')
                filename = os.path.basename(file)

                # ë‚ ì§œ ì¶”ì¶œ
                date_match = re.search(r'(\d{8})', filename)
                if date_match:
                    date = date_match.group(1)
                    if date not in date_groups:
                        date_groups[date] = []
                    date_groups[date].append({
                        'file': filename,
                        'content': content,
                        'path': file
                    })

            # ë‚ ì§œë³„ í†µí•©
            for date, files in date_groups.items():
                consolidated_file = logs_path / f"council_{date}_consolidated.md"

                with open(consolidated_file, 'w', encoding='utf-8') as f:
                    f.write(f"# Council Logs - {date}\n\n")
                    f.write(f"**í†µí•©ì¼**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
                    f.write(f"**ì›ë³¸ íŒŒì¼ ìˆ˜**: {len(files)}ê°œ\n\n")
                    f.write("---\n\n")

                    for idx, item in enumerate(files, 1):
                        f.write(f"## Session {idx}: {item['file']}\n\n")
                        f.write(item['content'])
                        f.write("\n\n---\n\n")

                # ì›ë³¸ íŒŒì¼ ì‚­ì œ
                for item in files:
                    os.remove(item['path'])
                    self.deleted_count += 1

                print(f"âœ… {date}: {len(files)}ê°œ council ë¡œê·¸ â†’ 1ê°œë¡œ í†µí•©")
                self.consolidated_count += 1

    def consolidate_blueprints(self):
        """Minimal Life ë¸”ë£¨í”„ë¦°íŠ¸ í†µí•©"""
        print("\nğŸ“˜ Minimal Life ë¸”ë£¨í”„ë¦°íŠ¸ í†µí•© ì‹œì‘...")

        blueprint_files = glob.glob(str(self.content_path / "minimal_life*.md"))

        if blueprint_files:
            # í†µí•© íŒŒì¼ ìƒì„±
            consolidated_file = self.content_path / "minimal_life_complete_guide.md"

            with open(consolidated_file, 'w', encoding='utf-8') as f:
                f.write("# Minimal Life - Complete Guide v3.0\n\n")
                f.write(f"**í†µí•©ì¼**: {datetime.now().strftime('%Y-%m-%d')}\n")
                f.write(f"**ì›ë³¸ íŒŒì¼ ìˆ˜**: {len(blueprint_files)}ê°œ\n\n")
                f.write("---\n\n")

                for file in blueprint_files:
                    filename = os.path.basename(file)
                    content = Path(file).read_text(encoding='utf-8')

                    # ì„¹ì…˜ ì œëª© ê²°ì •
                    if "strategy" in filename.lower():
                        section = "## Part 1: Strategy & Insight"
                    elif "visual" in filename.lower():
                        section = "## Part 2: Visual Guide"
                    elif "narrative" in filename.lower():
                        section = "## Part 3: Narrative"
                    elif "tech" in filename.lower():
                        section = "## Part 4: Technical Blueprint"
                    else:
                        section = f"## {filename}"

                    f.write(f"{section}\n\n")
                    f.write(f"*ì›ë³¸: {filename}*\n\n")
                    f.write(content)
                    f.write("\n\n---\n\n")

            # ì›ë³¸ íŒŒì¼ ì‚­ì œ
            for file in blueprint_files:
                os.remove(file)
                self.deleted_count += 1

            print(f"âœ… Minimal Life: {len(blueprint_files)}ê°œ â†’ 1ê°œë¡œ í†µí•©")
            self.consolidated_count += 1

    def extract_timestamp(self, filename):
        """íŒŒì¼ëª…ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ"""
        match = re.search(r'(\d{8}_\d{6})', filename)
        if match:
            return match.group(1)
        return filename

    def final_report(self):
        """ìµœì¢… ë³´ê³ ì„œ"""
        print("\n" + "="*50)
        print("ğŸ“Š í†µí•© ì™„ë£Œ ë³´ê³ ì„œ")
        print("="*50)

        # í˜„ì¬ MD íŒŒì¼ ìˆ˜ ê³„ì‚°
        all_md_files = glob.glob(str(self.base_path / "**/*.md"), recursive=True)

        # .git í´ë” ì œì™¸
        all_md_files = [f for f in all_md_files if ".git" not in f and "node_modules" not in f]

        print(f"âœ… í†µí•©ëœ íŒŒì¼ ê·¸ë£¹: {self.consolidated_count}ê°œ")
        print(f"ğŸ—‘ï¸ ì‚­ì œëœ íŒŒì¼: {self.deleted_count}ê°œ")
        print(f"ğŸ“ ì „ì²´ MD íŒŒì¼: {len(all_md_files)}ê°œ")

        if len(all_md_files) <= 100:
            print("\nğŸ‰ ëª©í‘œ ë‹¬ì„±! 100ê°œ ì´í•˜ë¡œ ì¶•ì†Œ ì„±ê³µ")
        else:
            print(f"\nâš ï¸ ì¶”ê°€ ì •ë¦¬ í•„ìš”: {len(all_md_files) - 100}ê°œ ë” ì¤„ì—¬ì•¼ í•¨")

    def run(self):
        """ì „ì²´ í†µí•© í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸš€ 97layerOS íŒŒì¼ í†µí•© ì‹œì‘...\n")

        # 1. Telegram ëŒ€í™” í†µí•©
        self.consolidate_telegram_by_date()

        # 2. Council ë¡œê·¸ í†µí•©
        self.consolidate_council_logs()

        # 3. Blueprint í†µí•©
        self.consolidate_blueprints()

        # 4. ìµœì¢… ë³´ê³ 
        self.final_report()


if __name__ == "__main__":
    consolidator = FileConsolidator()
    consolidator.run()