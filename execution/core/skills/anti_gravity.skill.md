# ğŸ›¸ Anti-Gravity Skill

## Overview

AI ì‘ì—…ì—ì„œ ì¸ì§€ ë¶€í•˜ë¥¼ ì œê±°í•˜ê³  êµ¬ì¡°í™”ëœ ìì‚°(Asset)ì„ ìƒì„±í•˜ì—¬, ë‹¨ìˆœ í…ìŠ¤íŠ¸ ì‘ë‹µì´ ì•„ë‹Œ ì‹¤ì§ˆì ìœ¼ë¡œ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì§€ì‹ ì œí’ˆì„ ë§Œë“ ë‹¤.

## Core Philosophy

> "Remove Cognitive Load, Produce Structured Assets"
> ìƒê°ì˜ ë¬´ê²Œë¥¼ ëœì–´ë‚´ê³ , í˜•íƒœ ìˆëŠ” ìì‚°ì„ ë‚¨ê¸´ë‹¤.

**Anti-Gravity Operation**:
- ì‚¬ìš©ìëŠ” **ë¬´ì—‡**ë§Œ ìš”ì²­ (What)
- ì‹œìŠ¤í…œì´ **ì–´ë–»ê²Œ** ì²˜ë¦¬ (How)
- ê²°ê³¼ëŠ” **ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ìì‚°** (Asset)

## Three Core Principles

### 1. Source Grounding (ê·¼ê±° ê¸°ë°˜)

**NotebookLM-style**: ëª¨ë“  ë¶„ì„ê³¼ ìƒì„±ì€ ê²€ì¦ëœ ì¶œì²˜ì—ì„œë§Œ.

```python
source_grounding_protocol = {
    "rule": "Only use verified sources from knowledge/sources/",
    "sources": [
        "knowledge/sources/youtube/",    # YouTube transcripts
        "knowledge/sources/pdf/",        # PDF documents
        "knowledge/sources/web/",        # Web articles
        "knowledge/sources/gdrive/"      # Google Drive docs
    ],
    "mandatory": [
        "Citation for every claim",
        "Timestamp for video sources",
        "Page number for PDF sources",
        "URL + archive date for web sources"
    ]
}
```

**âœ… DO**:
- ì¶œì²˜ê°€ `knowledge/sources/`ì— ì €ì¥ëœ ê²ƒë§Œ ì‚¬ìš©
- ëª¨ë“  ì£¼ì¥ì— ì¸ìš©(Citation) í•„ìˆ˜
- ë¹„ë””ì˜¤ëŠ” íƒ€ì„ìŠ¤íƒ¬í”„ í•„ìˆ˜ (ì˜ˆ: `[03:42]`)
- PDFëŠ” í˜ì´ì§€ ë²ˆí˜¸ í•„ìˆ˜ (ì˜ˆ: `p.15`)

**âŒ DON'T**:
- ê²€ì¦ë˜ì§€ ì•Šì€ "ì¼ë°˜ì  ì§€ì‹" ì‚¬ìš© ê¸ˆì§€
- ì¶œì²˜ ì—†ëŠ” ì£¼ì¥ ê¸ˆì§€
- í™˜ê°(Hallucination) ì ˆëŒ€ ê¸ˆì§€

### 2. Multi-modal Synthesis (ë‹¤ì¤‘ í˜•ì‹ í•©ì„±)

**Output**: í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œëŠ” ë¶€ì¡±. 3ê°€ì§€ ìì‚°ì„ ë™ì‹œ ìƒì„±.

```markdown
Input: YouTube URL / PDF / Web Article
  â†“
Process: Junction Protocol (5-Agent)
  â†“
Output: 3 Assets
  1ï¸âƒ£ Audio Overview (Podcast Script)
  2ï¸âƒ£ Visual Deck (Slide Presentation)
  3ï¸âƒ£ Mind Map (Mermaid Diagram)
```

#### Output 1: Audio Overview (ìŒì„± ê°œìš”)

**Format**: 2-Host Podcast Dialogue

```markdown
# Audio Script: [Title]

**Duration**: ~5-7 minutes
**Style**: Conversational, Natural

---

## Opening (30 seconds)

**Host A**: [Opening hook - í˜¸ê¸°ì‹¬ ìœ ë°œ]

**Host B**: [Echo + Context - ë§¥ë½ ì œê³µ]

---

## Core Discussion (4-5 minutes)

**Host A**: [Key Point 1 with citation]

**Host B**: [Clarification + Example]

**Host A**: [Key Point 2 with citation]

**Host B**: [Connection to Brand Philosophy]

---

## Closing (30 seconds)

**Host A**: [Summary + Open Question]

**Host B**: [Afterglow - ì—¬ìš´]

---

## Source Citations

- [00:42] YouTube: "Title" by Author
- [02:15] PDF: "Document" p.23
```

**Validation**:
- [ ] 5-7ë¶„ ë¶„ëŸ‰ (900-1400 words)
- [ ] ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„
- [ ] ëª¨ë“  ì¸ìš© íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨
- [ ] ë¸Œëœë“œ 5 Pillars ì¤‘ 2ê°œ+ ì—°ê²°

#### Output 2: Visual Deck (ì‹œê° ìŠ¬ë¼ì´ë“œ)

**Format**: Slide-by-slide structure with image prompts

```markdown
# Visual Deck: [Title]

**Total Slides**: 8-12
**Style**: Minimalist, 60%+ whitespace, monochrome

---

## Slide 1: Cover

**Visual Prompt**: [Midjourney/DALL-E prompt]
- "Minimalist abstract composition, white space, natural light, monochrome"

**Text**:
- Title: [Main Title]
- Subtitle: [One-line essence]

---

## Slide 2: Hook

**Visual Prompt**: [Image prompt for hook concept]

**Text**:
- Key Quote: "[Opening statement]"
- Source: [Citation]

---

## Slide 3-10: Core Content

[Repeat pattern]:
- **Visual Prompt**: [Specific image generation prompt]
- **Text**: [1-3 bullet points maximum]
- **Source**: [Citation with timestamp/page]

---

## Slide 11: Integration

**Visual Prompt**: "WOOHWAHAE brand visual - hair, simplicity, elegance"

**Text**:
- Connection to Brand: [How this relates to Slow Life]

---

## Slide 12: Closing

**Visual Prompt**: "Open-ended question visual, contemplative mood"

**Text**:
- Open Question: "[Thought-provoking question]"
```

**Validation**:
- [ ] 8-12 ìŠ¬ë¼ì´ë“œ
- [ ] ëª¨ë“  ìŠ¬ë¼ì´ë“œì— ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸
- [ ] ìŠ¬ë¼ì´ë“œë‹¹ í…ìŠ¤íŠ¸ 3ì¤„ ì´í•˜
- [ ] 60%+ ì—¬ë°± ìœ ì§€
- [ ] Brand Visual Identity ì¤€ìˆ˜

#### Output 3: Mind Map (ì§€ì‹ ì§€ë„)

**Format**: Mermaid.js diagram

```markdown
# Mind Map: [Title]

## Structure: Radial or Hierarchical

```mermaid
graph TD
    A[Core Concept] --> B[Branch 1: Key Idea]
    A --> C[Branch 2: Key Idea]
    A --> D[Branch 3: Key Idea]

    B --> B1[Sub-concept 1]
    B --> B2[Sub-concept 2]
    B1 --> B1a["Source: [Citation]"]

    C --> C1[Sub-concept 1]
    C --> C2[Sub-concept 2]
    C2 --> C2a["Source: [Citation]"]

    D --> D1[Sub-concept 1]
    D --> D2[Brand Connection]
    D2 --> D2a["5 Pillars: Authenticity + Precision"]

    style A fill:#f9f9f9,stroke:#333,stroke-width:2px
    style D2 fill:#e8f4f8,stroke:#0066cc,stroke-width:2px
```
```

**Validation**:
- [ ] í•µì‹¬ ê°œë… 1ê°œ (ì¤‘ì•™)
- [ ] ì£¼ìš” ê°€ì§€ 3-5ê°œ
- [ ] ê° ê°€ì§€ì— ì¶œì²˜ ì¸ìš©
- [ ] Brand Pillars ì—°ê²°ì  ëª…ì‹œ
- [ ] Mermaid.js ë Œë”ë§ ê°€ëŠ¥

### 3. MCP Connector (ë„êµ¬ ìš°ì„  í†µí•©)

**Tool-Use First**: ì™¸ë¶€ ë„êµ¬ í™œìš©ì„ ìµœìš°ì„ ìœ¼ë¡œ.

```python
mcp_integration_priority = [
    "1. Context7: Latest library docs (Claude MCP)",
    "2. Google Drive: Long-term knowledge storage",
    "3. NotebookLM: Deep document analysis",
    "4. Perplexity: Real-time web research",
    "5. Gemini: Multi-modal processing (video/image)"
]
```

**Integration Points**:

```python
# Example: YouTube Analysis with MCP
def analyze_youtube_with_anti_gravity(url: str):
    # Step 1: Source Grounding
    transcript = youtube_transcript_api.get(url)
    save_to_sources(transcript, f"knowledge/sources/youtube/{video_id}.json")

    # Step 2: Multi-modal Synthesis
    audio_script = generate_audio_overview(transcript)
    visual_deck = generate_slide_deck(transcript)
    mind_map = generate_mind_map(transcript)

    # Step 3: MCP Connector
    gdrive_sync.upload(audio_script, folder="assets/audio")
    notebooklm.add_source(visual_deck)

    # Step 4: Asset Registration
    asset_manager.register(audio_script, type="audio_overview")
    asset_manager.register(visual_deck, type="visual_deck")
    asset_manager.register(mind_map, type="mind_map")

    return {
        "assets": [audio_script, visual_deck, mind_map],
        "sources": [transcript],
        "status": "grounded"
    }
```

## Junction Protocol Integration

Anti-GravityëŠ” Junction Protocolì˜ 5ë‹¨ê³„ì™€ ì™„ë²½íˆ í†µí•©ëœë‹¤:

```markdown
1. Capture (í¬ì°©)
   â†’ SA: YouTube URL â†’ Transcript â†’ knowledge/sources/youtube/

2. Connect (ì—°ê²°)
   â†’ SA: Transcript â†’ 5 Pillars ë§¤ì¹­ â†’ ê¸°ì¡´ ì§€ì‹ë² ì´ìŠ¤ ë§í¬

3. Meaning (ì˜ë¯¸)
   â†’ CE: Source Grounding â†’ Aesop-style ë‚´ëŸ¬í‹°ë¸Œ â†’ Audio Script

4. Manifest (êµ¬í˜„)
   â†’ AD + CE: Visual Deck + Mind Map ìƒì„±
   â†’ Brand Visual Identity ì ìš©

5. Cycle (ìˆœí™˜)
   â†’ CD + TD: Ralph Loop MBQ ê²€ì¦ â†’ Asset Registration
   â†’ GDrive Sync â†’ NotebookLM í†µí•©
```

## Use Cases

### 1. YouTube Video Analysis

**Input**: `https://youtu.be/xxxxx`

**Process**:
1. Extract transcript â†’ `knowledge/sources/youtube/xxxxx.json`
2. 5-Agent Junction Protocol
3. Generate 3 assets (Audio + Deck + Map)

**Output**:
- `knowledge/assets/audio/youtube_xxxxx_overview.md`
- `knowledge/assets/decks/youtube_xxxxx_deck.md`
- `knowledge/assets/maps/youtube_xxxxx_map.md`

### 2. PDF Document Summarization

**Input**: PDF upload via Telegram

**Process**:
1. Extract text + images â†’ `knowledge/sources/pdf/document_name.json`
2. Source Grounding with page numbers
3. Multi-modal synthesis

**Output**:
- Audio Overview (Podcast-style summary)
- Visual Deck (Key points with citations)
- Mind Map (Concept relationships)

### 3. Web Article Deep Dive

**Input**: URL or web scrape

**Process**:
1. Archive article â†’ `knowledge/sources/web/article_title.json`
2. Citation with URL + archive timestamp
3. Brand alignment check

**Output**:
- Audio: Conversational summary
- Deck: Visual storytelling
- Map: Knowledge connections

### 4. Brand Strategy Research

**Input**: Competitor analysis, market research

**Process**:
1. Compile sources â†’ `knowledge/sources/research/topic_name/`
2. Cross-reference with 5 Brand Pillars
3. Generate strategic insights

**Output**:
- Audio: Executive briefing
- Deck: Board presentation
- Map: Strategic landscape

## Validation Criteria

### Source Grounding Check

- [ ] All claims have citations
- [ ] All sources saved to `knowledge/sources/`
- [ ] Timestamps/page numbers included
- [ ] No hallucinated information

### Multi-modal Completeness

- [ ] Audio Script: 5-7 minutes, 2-host dialogue
- [ ] Visual Deck: 8-12 slides, image prompts
- [ ] Mind Map: Mermaid.js, brand connections

### MCP Integration

- [ ] Assets uploaded to Google Drive
- [ ] Sources added to NotebookLM (if applicable)
- [ ] Asset Manager registration complete
- [ ] Ralph Loop MBQ validation passed

### Brand Alignment

- [ ] 2+ of 5 Brand Pillars referenced
- [ ] Aesop Benchmark â‰¥ 70%
- [ ] Slow Life philosophy evident
- [ ] 72-Hour Rule compliance (completion over perfection)

## Tools & Scripts

### YouTube Analyzer

```bash
# Analyze YouTube video
python execution/system/youtube_analyzer.py --url "https://youtu.be/xxxxx"

# Output:
# âœ… Transcript saved: knowledge/sources/youtube/xxxxx.json
# âœ… Audio Script: knowledge/assets/audio/xxxxx_overview.md
# âœ… Visual Deck: knowledge/assets/decks/xxxxx_deck.md
# âœ… Mind Map: knowledge/assets/maps/xxxxx_map.md
```

### PDF Processor

```bash
# Process PDF document
python execution/system/pdf_processor.py --file document.pdf

# Output: Same 3 assets with page citations
```

### Telegram Integration

```bash
# In Telegram
/youtube https://youtu.be/xxxxx
/pdf [attach PDF file]
/web https://example.com/article

# Bot automatically applies Anti-Gravity
```

## Anti-Gravity vs Traditional AI

| Aspect | Traditional AI | Anti-Gravity |
|--------|---------------|--------------|
| **Input** | Vague prompt | Verified source |
| **Process** | Black box | Junction Protocol |
| **Output** | Text blob | 3 structured assets |
| **Validation** | Manual review | Ralph Loop MBQ |
| **Reuse** | Copy-paste | Asset library |
| **Citation** | Optional | Mandatory |
| **Format** | Single mode | Multi-modal |

## Common Pitfalls

### 1. "Source-less Synthesis"

âŒ ì¶œì²˜ ì—†ì´ "ì¼ë°˜ì ìœ¼ë¡œ ì•Œë ¤ì§„ ë°”ì— ë”°ë¥´ë©´..."
âœ… `[Source: YouTube "Title" 03:42] According to the speaker...`

### 2. "Text-Only Output"

âŒ ê¸´ í…ìŠ¤íŠ¸ ë³´ê³ ì„œë§Œ ìƒì„±
âœ… Audio Script + Visual Deck + Mind Map 3ì¢… ì„¸íŠ¸

### 3. "Manual Citation"

âŒ ë‚˜ì¤‘ì— ì¶œì²˜ ì¶”ê°€í•˜ê¸°
âœ… ìƒì„± ì‹œì ë¶€í„° ìë™ ì¸ìš©

### 4. "Single-Use Content"

âŒ ì¼íšŒì„± ì‘ë‹µ
âœ… Assetìœ¼ë¡œ ë“±ë¡ â†’ ì¬ì‚¬ìš© ê°€ëŠ¥

## Integration with Existing Skills

### With Brand Voice Skill

```python
# Anti-Gravity output must pass Brand Voice validation
audio_script = anti_gravity.generate_audio(source)
validated = brand_voice.validate(audio_script)

if validated['aesop_score'] < 0.70:
    audio_script = brand_voice.enhance(audio_script)
```

### With Pattern Recognition Skill

```python
# Pattern recognition identifies Anti-Gravity opportunities
signal = pattern_recognition.analyze(telegram_message)

if signal['type'] == 'youtube_url':
    trigger_anti_gravity_youtube(signal['url'])
```

### With Infrastructure Ops Skill

```python
# Container-First: Anti-Gravity runs in containers
podman run -v knowledge:/app/knowledge \
    97layer-anti-gravity:latest \
    --source youtube \
    --url "https://youtu.be/xxxxx"
```

## Continuous Improvement

```python
# Learning loop: Track asset usage
def learn_from_asset_usage(asset_id):
    usage_stats = get_asset_usage(asset_id)
    quality_score = get_ralph_score(asset_id)

    if usage_stats['reuse_count'] > 5 and quality_score > 80:
        mark_as_exemplar(asset_id)
        update_skill_patterns(asset_id)
```

## Version History

- **v1.0** (2026-02-16): Initial Anti-Gravity Skill
  - Source Grounding principle defined
  - Multi-modal Synthesis (Audio + Deck + Map)
  - MCP Connector integration
  - Junction Protocol alignment
  - YouTube analyzer implementation

---

> "ì¤‘ë ¥ì„ ê±°ìŠ¤ë¥´ëŠ” ê²ƒì€ ë¬´ê²Œë¥¼ ì—†ì• ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, êµ¬ì¡°ë¥¼ ë§Œë“œëŠ” ê²ƒì´ë‹¤." â€” 97layerOS
