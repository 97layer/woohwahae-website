import time
import json
import os
import sys
from datetime import datetime
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parent.parent
TASK_FILE = BASE_DIR / "task_status.json"

# ì—ì´ì „íŠ¸ ì´ë¦„ â†’ í‚¤ ë§¤í•‘ (ëª¨ë“ˆ ë ˆë²¨ ìƒìˆ˜)
AGENT_KEY_MAP = {
    "Strategy_Analyst": "SA",
    "Creative_Director": "CD",
    "Technical_Director": "TD",
    "Chief_Editor": "CE",
    "Art_Director": "AD",
}

# libs/ ëª¨ë“ˆ ì ‘ê·¼ì„ ìœ„í•´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
if str(BASE_DIR) not in sys.path:
    sys.path.insert(0, str(BASE_DIR))

# Lazy-load AI to avoid circular deps
_ai = None
_router = None
_telegram_token = None

def _get_ai():
    global _ai
    if _ai is None:
        import sys
        sys.path.insert(0, str(BASE_DIR))
        from libs.ai_engine import AIEngine
        from libs.core_config import AI_MODEL_CONFIG
        _ai = AIEngine(AI_MODEL_CONFIG)
    return _ai

def _get_syncer():
    from execution.system.sync_status import SystemSynchronizer
    return SystemSynchronizer(agent_name="Technical_Director")

def _get_router():
    global _router
    if _router is None:
        from libs.agent_router import AgentRouter
        _router = AgentRouter(_get_ai())
    return _router

def _get_token():
    global _telegram_token
    if _telegram_token is None:
        from libs.core_config import TELEGRAM_CONFIG
        _telegram_token = TELEGRAM_CONFIG["BOT_TOKEN"]
    return _telegram_token

def _broadcast_to_telegram(text: str):
    """Broadcasting utility using Notifier."""
    try:
        from libs.notifier import Notifier
        notifier = Notifier()
        notifier.broadcast(text)
    except Exception as e:
        print(f"[Telegram Error] {e}")

def _check_rituals(status: dict):
    """Checks RITUALS_CONFIG and triggers tasks if conditions met."""
    from libs.core_config import RITUALS_CONFIG
    
    now = datetime.now()
    current_hour = now.hour
    current_weekday = now.weekday()  # 0=Monday, 6=Sunday
    today_str = now.strftime("%Y-%m-%d")
    
    # Ensure 'rituals_log' exists in status
    if "rituals_log" not in status:
        status["rituals_log"] = {}

    for ritual_name, config in RITUALS_CONFIG.items():
        # Check if already done today
        last_run = status["rituals_log"].get(ritual_name)
        if last_run == today_str:
            continue
            
        # Check Time Conditions
        trigger_hour = config.get("trigger_hour")
        trigger_weekday = config.get("trigger_weekday")
        
        # Hour check (Trigger if current hour matches)
        if trigger_hour is not None and current_hour != trigger_hour:
            continue
            
        # Weekday check (If specified)
        if trigger_weekday is not None and current_weekday != trigger_weekday:
            continue
            
        # Trigger Condition Met!
        print(f"[{datetime.now()}] [Ritual] Triggering {ritual_name}...")
        
        new_task = {
            "id": f"ritual_{ritual_name}_{int(time.time())}",
            "type": config.get("task_type", "GENERAL"),
            "agent": config.get("agent", "System"),
            "instruction": config.get("instruction", ""),
            "council": config.get("council", False)
        }
        
        status.setdefault("pending_tasks", []).append(new_task)
        status["rituals_log"][ritual_name] = today_str
        
        # Notify via Telegram about Ritual Start
        _broadcast_to_telegram(f"ğŸ•¯ï¸ [Ritual Started] {ritual_name}\n{config.get('instruction')[:50]}...")

def _get_chat_ids() -> list:
    """task_statusì—ì„œ ì•Œë¦¼ ë°›ì„ chat_id ëª©ë¡ ì¡°íšŒ"""
    status = _load_status()
    return status.get("telegram_chat_ids", [])

def _load_status() -> dict:
    if not TASK_FILE.exists():
        return {"pending_tasks": [], "completed_tasks": []}
    with open(TASK_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

def _save_status(status: dict):
    status["last_active"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(TASK_FILE, 'w', encoding='utf-8') as f:
        json.dump(status, f, indent=4, ensure_ascii=False)

def _handle_consolidation(task: dict) -> str:
    """
    Handles the NIGHTLY_CONSOLIDATION task.
    Aggregates all raw signals from the last 24h and generates a pattern update.
    """
    try:
        raw_signals_dir = BASE_DIR / "knowledge" / "raw_signals"
        today_str = datetime.now().strftime("%Y-%m-%d")
        
        # Find files modified today
        recent_signals = []
        for f in raw_signals_dir.glob("*.md"):
            if f.stat().st_mtime > time.time() - 86400:  # Last 24 hours
                with open(f, "r", encoding="utf-8") as rf:
                    content = rf.read()
                    recent_signals.append(f"FileName: {f.name}\n{content[:2000]}") # Truncate per file
        
        if not recent_signals:
            return "No new signals found in the last 24 hours."

        aggregated_content = "\n---\n".join(recent_signals)
        
        instruction = task.get("instruction", "")
        prompt = f"""
        {instruction}

        [Collected Raw Signals (Last 24h)]
        {aggregated_content}
        
        [Output Logic]
        1. Summarize key themes.
        2. Identify recurring patterns.
        3. Suggest strategic actions for tomorrow.
        """
        
        ai = _get_ai()
        result = ai.generate_response(prompt)
        
        # Save to patterns
        pattern_file = BASE_DIR / "knowledge" / "patterns" / f"daily_insight_{today_str}.md"
        pattern_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(pattern_file, "w", encoding="utf-8") as pf:
            pf.write(f"# Daily Insight ({today_str})\n\n{result}")
            
        return f"Consolidation Complete. Saved to {pattern_file}"

    except Exception as e:
        return f"Consolidation Failed: {e}"

def _get_shared_memory() -> str:
    """
    ìµœê·¼ ìˆ˜ì§‘ëœ ì§€ì‹ íŒ¨í„´(Patterns)ì—ì„œ í•µì‹¬ ìš”ì•½ì„ ì¶”ì¶œ
    """
    try:
        patterns_dir = BASE_DIR / "knowledge" / "patterns"
        if not patterns_dir.exists():
            return "No shared patterns available."
        
        recent_patterns = sorted(patterns_dir.glob("*.md"), key=os.path.getmtime, reverse=True)[:3]
        summaries = []
        for f in recent_patterns:
            with open(f, "r", encoding="utf-8") as pf:
                # ì²« 500ì í˜¹ì€ ìš”ì•½ ì„¹ì…˜ ì¶”ì¶œ
                content = pf.read()
                summaries.append(f"[{f.name}] {content[:500]}")
        
        return "\n".join(summaries)
    except Exception as e:
        return f"Shared memory retrieval failed: {e}"

def _get_project_context() -> str:
    """
    í˜„ì¬ í”„ë¡œì íŠ¸ì˜ ì‹¤ì œ ìƒíƒœ(Task, Vision, Knowledge ë“±)ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì§€ì¹¨ ì£¼ì…ìš© í…ìŠ¤íŠ¸ ìƒì„±
    """
    try:
        from pathlib import Path
        import json
        
        status = _load_status()
        pending = status.get("pending_tasks", [])
        completed = status.get("completed_tasks", [])
        
        vision_path = BASE_DIR / "VISION.md"
        vision = ""
        if vision_path.exists():
            with open(vision_path, "r", encoding="utf-8") as f:
                vision = f.read()[:500]
        
        assets_dir = BASE_DIR / "knowledge" / "assets"
        recent_assets = []
        if assets_dir.exists():
            for f in sorted(assets_dir.rglob("*.md"), key=os.path.getmtime, reverse=True)[:5]:
                recent_assets.append(f.name)

        shared_memory = _get_shared_memory()

        context = f"""
        [Current Project Reality]
        - Vision Summary: {vision}
        - Pending Tasks: {len(pending)} (First: {pending[0]['instruction'] if pending else 'None'})
        - Recently Completed: {completed[-3:] if completed else 'None'}
        - Recent Knowledge Assets: {', '.join(recent_assets)}
        
        [Shared Memory / Recent Patterns]
        {shared_memory}
        """
        return context
    except Exception as e:
        return f"Context collection failed: {e}"

def execute_agent(task: dict) -> str:
    """
    ì‹¤ì œ ì—ì´ì „íŠ¸ LLM í˜¸ì¶œ
    """
    # Special Handler for Skill Execution
    if task.get("type") == "SKILL":
        return _handle_skill_execution(task)
    # Special Handler for Consolidation
    elif task.get("type") == "CONSOLIDATION":
        return _handle_consolidation(task)
    elif task.get("type") == "AUTONOMOUS_DEV":
        res = _handle_autonomous_dev(task)
        _broadcast_to_telegram(f"ğŸ¤– ììœ¨ ì‹œìŠ¤í…œ ì§„í™” ë³´ê³ :\n\n{res}")
        return res
    elif task.get("type") == "DIAGNOSTIC":
        res = _handle_diagnostic(task)
        if "âŒ" in res or "âš ï¸" in res:
            _broadcast_to_telegram(f"ğŸ›¡ï¸ ê°€ë””ì–¸ ê¸´ê¸‰ ì ê²€ ë¦¬í¬íŠ¸:\n\n{res}")
        return res
    elif task.get("type") == "PUBLISH_CHECK":
        res = _handle_publish_check(task)
        if res and ("ìë™ íê¸°" in res or "CD ê²°ì • í•„ìš”" in res):
            _broadcast_to_telegram(f"â° [72h Rule]\n\n{res}")
        return res
    elif task.get("type") == "INSTAGRAM_PUBLISH":
        res = _handle_instagram_publish(task)
        if res and "ë°œí–‰ ì™„ë£Œ" in res:
            _broadcast_to_telegram(f"ğŸ“¸ [Instagram ë°œí–‰]\n\n{res}")
        return res
    elif task.get("type") == "INSIGHT":
        # Insight tasks are handled by standard execute_agent flow but generate a proactive report
        pass

    agent_name = task.get("agent", "CD")
    agent_key = AGENT_KEY_MAP.get(agent_name, "CD")
    instruction = task.get("instruction", "")

    router = _get_router()
    system_prompt = router.build_system_prompt(agent_key)
    ai = _get_ai()

    # Context Grounding (Hallucination ë°©ì§€)
    project_context = _get_project_context()
    grounded_instruction = f"""
    {project_context}

    [Instruction]
    {instruction}

    ìœ„ì˜ [Current Project Reality]ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ì„ í•˜ì‹­ì‹œì˜¤.
    ë§Œì•½ í˜„ì¬ í”„ë¡œì íŠ¸ì™€ ê´€ê³„ì—†ëŠ” ë‚´ìš©(ì˜ˆ: Athena, Hermes ë“± ê°€ê³µì˜ ì´ë¦„)ì„ ì§€ì–´ë‚´ì§€ ë§ˆì‹­ì‹œì˜¤.
    """

    print(f"[{datetime.now()}] [{agent_key}] íƒœìŠ¤í¬ ì‹¤í–‰: {instruction[:60]}...")

    result = ai.generate_response(
        prompt=grounded_instruction,
        system_instruction=system_prompt
    )

    print(f"[{datetime.now()}] [{agent_key}] ì™„ë£Œ.")
    return result

def _handle_autonomous_dev(task: dict) -> str:
    """Runs the autonomous_developer.py script."""
    try:
        import subprocess
        script_path = BASE_DIR / "execution" / "autonomous_developer.py"
        result = subprocess.run([sys.executable, str(script_path)], capture_output=True, text=True)
        if result.returncode == 0:
            return f"Autonomous Development Cycle Complete.\n{result.stdout}"
        else:
            return f"Autonomous Development Failed: {result.stderr}"
    except Exception as e:
        return f"Autonomous Development Error: {e}"

def _handle_diagnostic(task: dict) -> str:
    """Runs common diagnostics via SystemGuardian."""
    try:
        from libs.system_guardian import SystemGuardian
        guardian = SystemGuardian(str(BASE_DIR))
        return guardian.get_system_report()
    except Exception as e:
        return f"Diagnostic Failed: {e}"

def _handle_publish_check(task: dict) -> str:
    """Runs auto_publisher to check 72h rule."""
    try:
        import sys
        script_path = BASE_DIR / "execution" / "auto_publisher.py"

        # Import and run directly for better control
        sys.path.insert(0, str(BASE_DIR / "execution"))
        from auto_publisher import AutoPublisher

        publisher = AutoPublisher()
        violations = publisher.check_72h_rule()

        if not violations:
            return ""

        # Process violations
        result_lines = []
        for v in violations:
            if v["status"] == "violation":
                # 76h+ auto discard
                publisher.auto_discard(v["path"])
                result_lines.append(f"ğŸš¨ ìë™ íê¸°: {v['file']} ({v['elapsed_hours']}h)")
            else:
                # 72-76h warning
                result_lines.append(f"âš ï¸ CD ê²°ì • í•„ìš”: {v['file']} ({v['elapsed_hours']}h)")

        # Generate CD notification
        notification = publisher.notify_cd(violations)
        return "\n".join(result_lines) + "\n\n" + notification

    except Exception as e:
        return f"Publish Check Failed: {e}"

def _handle_instagram_publish(task: dict) -> str:
    """Runs instagram_publisher to publish scheduled content."""
    try:
        import subprocess
        script_path = BASE_DIR / "execution" / "instagram_publisher.py"

        result = subprocess.run(
            [sys.executable, str(script_path)],
            capture_output=True,
            text=True,
            timeout=300  # 5 min timeout
        )

        if result.returncode == 0:
            return f"Instagram ë°œí–‰ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ.\n{result.stdout}"
        else:
            return f"Instagram ë°œí–‰ ì‹¤íŒ¨: {result.stderr}"

    except subprocess.TimeoutExpired:
        return "Instagram ë°œí–‰ íƒ€ì„ì•„ì›ƒ (5ë¶„ ì´ˆê³¼)"
    except Exception as e:
        return f"Instagram Publish Failed: {e}"

def _handle_skill_execution(task: dict) -> str:
    """Executes a skill based on task specification."""
    try:
        from libs.skill_engine import SkillEngine
        skill_engine = SkillEngine()

        skill_id = task.get("skill_id")
        context = task.get("context", {})

        if not skill_id:
            return "Skill execution failed: No skill_id provided"

        print(f"[{datetime.now()}] [SKILL] Executing: {skill_id}")
        result = skill_engine.execute_skill(skill_id, context)

        if result.get("status") == "success":
            output_msg = f"Skill [{skill_id}] executed successfully.\n"
            if result.get("output_file"):
                output_msg += f"Output: {result['output_file']}"
            print(f"[{datetime.now()}] [SKILL] Success: {skill_id}")
            return output_msg
        else:
            error_msg = f"Skill [{skill_id}] failed: {result.get('message')}"
            print(f"[{datetime.now()}] [SKILL] Failed: {error_msg}")
            return error_msg

    except Exception as e:
        return f"Skill Execution Error: {e}"


def council_on_task(task: dict) -> str:
    """
    ë³µì¡í•œ íƒœìŠ¤í¬ëŠ” Synapse council_meetingìœ¼ë¡œ ì²˜ë¦¬
    """
    from libs.synapse import Synapse
    synapse = Synapse(_get_ai())
    topic = task.get("instruction", "")
    print(f"[{datetime.now()}] [COUNCIL] ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í† ë¡  ì‹œì‘: {topic[:60]}...")
    return synapse.council_meeting(topic)

def check_system_entropy():
    """ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€ ë° íƒœìŠ¤í¬ ì‹¤í–‰"""
    try:
        # Heartbeat for Dashboard
        syncer = _get_syncer()
        syncer.report_heartbeat(status="ACTIVE", current_task="ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€ ë° íƒœìŠ¤í¬ ìŠ¤ìº”")

        # -1. 72h Rule Check (Every Loop - Non-blocking)
        try:
            _handle_publish_check({})
        except Exception as pc_e:
            print(f"[Publish Check Error] {pc_e}")

        # 0. System Guardian: Self-Diagnostic
        try:
            from libs.system_guardian import SystemGuardian
            guardian = SystemGuardian(str(BASE_DIR))
            health_report = guardian.get_system_report()
            
            # If any critical daemon is down, notify or log error
            if "âŒ" in health_report:
                print(f"[Guardian Alert] {health_report}")
                # We can choose to notify user or attempt restart here
                # For now, let's just log it and potentially send a mini-alert
            
            # Update health in status
            status = _load_status()
            status["system_health"] = health_report
            _save_status(status)
        except Exception as sg_e:
            print(f"[Guardian Error] {sg_e}")

        # 0.5. Ingestion Loop (Gatekeeper) - Picking up new insights FIRST
        try:
            from execution import ingest_gatekeeper
            ingest_gatekeeper.process_inbox()
        except Exception as ig_e:
            print(f"[Gatekeeper Error] {ig_e}")

        # 1. Load Status AFTER ingestion to pick up circular actions
        status = _load_status()
        
        # Update heartbeat even if no tasks
        status["last_active"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        _save_status(status)

        # Check for Rituals (Scheduled Tasks)
        _check_rituals(status)
        _save_status(status)

        # ëŒ€ê¸° íƒœìŠ¤í¬ ì‹¤í–‰
        pending = status.get("pending_tasks", [])
        if not pending:
            print(f"[{datetime.now()}] [Standby] ëŒ€ê¸° ì¤‘ì¸ íƒœìŠ¤í¬ ì—†ìŒ.")
            return

        task = pending[0]
        use_council = task.get("council", False)

        # ì‹¤ì œ LLM ì‹¤í–‰
        if use_council:
            result = council_on_task(task)
        else:
            result = execute_agent(task)
            _archive_result(task, result)

        # íƒœìŠ¤í¬ ì™„ë£Œ ì²˜ë¦¬
        status["pending_tasks"].pop(0)
        status.setdefault("completed_tasks", []).append(f"{task['id']}_done")
        if use_council:
            status["last_council_result"] = result[:500]
        status["last_active"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        _save_status(status)

        # í…”ë ˆê·¸ë¨ ë³´ê³  (ê³ ì§€ëŠ¥ ë¸Œë¦¬í•‘ í¬ë§·)
        report_prompt = f"""
        97LAYERì˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ë¡œì„œ ë‹¤ìŒ ìˆ˜í–‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ë³´ê³ í•˜ì‹­ì‹œì˜¤.
        
        [ìˆ˜í—˜ ê²°ê³¼]
        ì—ì´ì „íŠ¸: {task.get('agent')}
        íƒ€ì…: {task.get('type')}
        ë‚´ìš©: {result[:1200]}
        
        [ì§€ì¹¨]
        1. 'íƒ€ì…:', 'ë‹´ë‹¹:', 'â—ˆ', '[ ]' ì™€ ê°™ì€ ê¸°ê³„ì  ë˜ëŠ” ìƒì§•ì ì¸ ë¨¸ë¦¬ë§ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
        2. ë‹µë³€ì€ ì¦‰ì‹œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥(Narrative)ìœ¼ë¡œ ì‹œì‘í•˜ì‹­ì‹œì˜¤.
        3. ëƒ‰ì² í•˜ê³  ê¶Œìœ„ ìˆëŠ” ì–´ì¡°ë¡œ í•µì‹¬ë§Œ ì „ë‹¬í•˜ë˜, ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ì—¬ ë³´ê³ í•˜ì‹­ì‹œì˜¤.
        4. ì´ ê²°ê³¼ê°€ í”„ë¡œì íŠ¸ì˜ íë¦„ìƒ ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°–ëŠ”ì§€ 1ë¬¸ì¥ìœ¼ë¡œ í•´ì„ì„ ë§ë¶™ì´ì‹­ì‹œì˜¤.
        5. ë³¼ë“œ(**)ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
        """
        briefing = _get_ai().generate_response(report_prompt)
        
        _broadcast_to_telegram(briefing)

        print(f"[{datetime.now()}] [Done] íƒœìŠ¤í¬ ì™„ë£Œ ë° ë³´ê³  ì „ì†¡.")

    except Exception as e:
        print(f"[{datetime.now()}] [Error] {e}")

def _archive_result(task: dict, content: str):
    """Saves the result of an autonomous task as a markdown asset."""
    try:
        task_type = task.get("type", "GENERAL").lower()
        date_str = datetime.now().strftime("%Y%m%d")
        timestamp = int(time.time())
        
        # Determine path based on type
        save_dir = BASE_DIR / "knowledge" / "assets" / task_type
        save_dir.mkdir(parents=True, exist_ok=True)
        
        filename = f"{task_type}_{date_str}_{timestamp}.md"
        filepath = save_dir / filename
        
        # Frontmatter + Content
        file_content = f"""---
id: {task.get('id')}
date: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
type: {task.get('type')}
agent: {task.get('agent')}
---

# {task.get('type')} Report

{content}
"""
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(file_content)
            
        print(f"[{datetime.now()}] [Archive] Saved asset to {filepath}")
        
    except Exception as e:
        print(f"[{datetime.now()}] [Archive Error] {e}")

def main_loop():
    print(f"[{datetime.now()}] === 97LAYER Technical Daemon (LLM Connected) Started ===")
    check_system_entropy()
    # Initial run for testing
    while True:
        try:
            time.sleep(600)  # 10ë¶„ ëŒ€ê¸°
            check_system_entropy()
        except KeyboardInterrupt:
            print("Daemon Stopped.")
            break
        except Exception as e:
            print(f"Loop Error: {e}")
            time.sleep(60)

if __name__ == "__main__":
    main_loop()
