#!/usr/bin/env python3
"""
97LAYER OS - Intelligent Telegram Bot
Google Gemini API integration
"""

import os
import json
import time
import urllib.request
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
import google.genai as genai

# Load environment
load_dotenv('/app/.env')

# Configuration
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not TOKEN:
    raise ValueError("âŒ TELEGRAM_BOT_TOKEN not found")
if not GEMINI_API_KEY:
    raise ValueError("âŒ GEMINI_API_KEY not found")

BASE_URL = f"https://api.telegram.org/bot{TOKEN}"
CHAT_MEMORY = Path("/app/knowledge/chat_memory/7565534667.json")

# Initialize Gemini with new API
client = genai.Client(api_key=GEMINI_API_KEY)

print("âœ… Gemini AI initialized")

def load_conversation_history():
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¡œë“œ (ìµœê·¼ 20ê°œ)"""
    if CHAT_MEMORY.exists():
        with open(CHAT_MEMORY, 'r', encoding='utf-8') as f:
            messages = json.load(f)
            return messages[-20:] if len(messages) > 20 else messages
    return []

def save_message(chat_id, text, role="user"):
    """ë©”ì‹œì§€ ì €ì¥"""
    CHAT_MEMORY.parent.mkdir(parents=True, exist_ok=True)

    messages = []
    if CHAT_MEMORY.exists():
        with open(CHAT_MEMORY, 'r', encoding='utf-8') as f:
            messages = json.load(f)

    messages.append({
        "timestamp": datetime.now().isoformat(),
        "role": role,
        "content": text
    })

    with open(CHAT_MEMORY, 'w', encoding='utf-8') as f:
        json.dump(messages, f, ensure_ascii=False, indent=2)

    print(f"ğŸ’¾ [{role}] {text[:50]}...")

def send_message(chat_id, text):
    """ë©”ì‹œì§€ ì „ì†¡"""
    url = f"{BASE_URL}/sendMessage"
    data = json.dumps({
        "chat_id": chat_id,
        "text": text
    }).encode('utf-8')

    req = urllib.request.Request(url, data=data)
    req.add_header('Content-Type', 'application/json')

    try:
        with urllib.request.urlopen(req) as response:
            print(f"ğŸ“¤ ì „ì†¡: {text[:50]}...")
            return True
    except Exception as e:
        print(f"ì „ì†¡ ì‹¤íŒ¨: {e}")
        return False

def generate_ai_response(user_message, context_messages):
    """Gemini AI ì‘ë‹µ ìƒì„±"""
    try:
        # Build context from history
        context = "ëŒ€í™” ê¸°ë¡:\n"
        for msg in context_messages[-10:]:  # Last 10 messages
            role = "ì‚¬ìš©ì" if msg["role"] == "user" else "AI"
            context += f"{role}: {msg['content']}\n"

        # System instruction + context + new message
        prompt = f"""ë‹¹ì‹ ì€ 97LAYER OSì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

íŠ¹ì§•:
- í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”
- ê°„ê²°í•˜ê³  ì‹¤ìš©ì ì¸ ë‹µë³€
- ë¶ˆí•„ìš”í•œ ê²©ì‹ ì—†ì´ í¸í•˜ê²Œ
- ì°½ì˜ì ì´ê³  ê¸°ìˆ ì ì¸ ì‘ì—… ì§€ì›

{context}

ì‚¬ìš©ì: {user_message}
AI:"""

        # Generate response with new API
        response = client.models.generate_content(
            model='models/gemini-2.5-flash',
            contents=prompt
        )
        return response.text

    except Exception as e:
        print(f"AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def process_command(chat_id, command):
    """ëª…ë ¹ì–´ ì²˜ë¦¬"""
    cmd = command.lower().split()[0]

    if cmd == "/start":
        return """ğŸ¤– 97LAYER OS Bot

Google Gemini AIì™€ í•¨ê»˜ ì‘ë™í•©ë‹ˆë‹¤.

ëª…ë ¹ì–´:
- /status - ì‹œìŠ¤í…œ ìƒíƒœ
- /clear - ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
- ì¼ë°˜ ë©”ì‹œì§€ - AIì™€ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”"""

    elif cmd == "/status":
        history = load_conversation_history()
        return f"""âœ… ì‹œìŠ¤í…œ ìƒíƒœ

ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ì»¨í…Œì´ë„ˆ: 97layer-workspace
AI ì—”ì§„: Google Gemini 2.5 Flash
ëŒ€í™” ê¸°ë¡: {len(history)}ê°œ ë©”ì‹œì§€"""

    elif cmd == "/clear":
        if CHAT_MEMORY.exists():
            CHAT_MEMORY.unlink()
        return "ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."

    else:
        return f"ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {cmd}\n/start ë¥¼ ì…ë ¥í•´ ë„ì›€ë§ì„ í™•ì¸í•˜ì„¸ìš”."

def main():
    print("=" * 60)
    print("ğŸ¤– 97LAYER OS Intelligent Bot (Gemini)")
    print("=" * 60)
    print(f"ğŸ“ Container: 97layer-workspace")
    print(f"ğŸ“‚ Memory: {CHAT_MEMORY}")
    print(f"ğŸ§  AI: Google Gemini 1.5 Flash")
    print("=" * 60)

    offset = None

    while True:
        try:
            url = f"{BASE_URL}/getUpdates?timeout=30"
            if offset:
                url += f"&offset={offset}"

            with urllib.request.urlopen(url, timeout=35) as response:
                result = json.loads(response.read())

                for update in result.get("result", []):
                    offset = update["update_id"] + 1

                    if "message" in update:
                        msg = update["message"]
                        chat_id = msg["chat"]["id"]
                        text = msg.get("text", "")

                        if text:
                            print(f"\nğŸ“© ë°›ìŒ: {text}")
                            save_message(chat_id, text, "user")

                            # Process message
                            if text.startswith("/"):
                                response = process_command(chat_id, text)
                            else:
                                # AI conversation
                                context = load_conversation_history()
                                response = generate_ai_response(text, context)

                            # Send response
                            send_message(chat_id, response)
                            save_message(chat_id, response, "assistant")

        except Exception as e:
            if "409" in str(e):
                print("âš ï¸ 409 Conflict - ë‹¤ë¥¸ ë´‡ì´ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. 10ì´ˆ ëŒ€ê¸°...")
                time.sleep(10)
            elif "timeout" in str(e).lower():
                # Normal timeout, just continue
                pass
            else:
                print(f"ì˜¤ë¥˜: {e}")
                time.sleep(5)

if __name__ == "__main__":
    main()
