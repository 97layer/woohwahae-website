#!/usr/bin/env python3
"""
HTML ì „ìˆ˜ì¡°ì‚¬ ìŠ¤í¬ë¦½íŠ¸
WOOHWAHAE ì›¹ì‚¬ì´íŠ¸ UI/UX/í…ìŠ¤íŠ¸ ì¼ê´€ì„± ê²€ì¦
"""

import os
import re
import json
from pathlib import Path
from bs4 import BeautifulSoup
from typing import Dict, List, Tuple

# ë¸Œëœë“œ ê¸°ì¤€
BRAND_TOKENS = {
    'colors': {
        'allowed': ['--bg', '--text', '--text-sub', '--text-faint', '--white', '--line', '--stone-dark', '--stone-mid', '--stone-light'],
        'prohibited': ['--navy'],  # ::selection, blockquoteë§Œ í—ˆìš©
        'hardcoded_patterns': [
            r'#[0-9A-Fa-f]{6}',  # hex colors
            r'rgb\(',
            r'rgba\('
        ]
    },
    'fonts': {
        'allowed': ['--font-body', '--font-mono', '--font-serif', '--font-serif-slab', 'Pretendard Variable', 'IBM Plex Mono', 'DM Mono', 'Crimson Text', 'Bitter'],
        'prohibited': ['Arial', 'sans-serif', 'serif']  # genericë§Œ ê¸ˆì§€, fallbackì€ í—ˆìš©
    },
    'spacing': {
        'tokens': ['--space-xs', '--space-sm', '--space-md', '--space-lg', '--space-xl', '--space-2xl']
    },
    'tone': {
        'archive': 'í•œë‹¤ì²´',  # ì‚¬ìƒ‰ì , ì—´ë¦° ê²°ë§
        'magazine': 'í•©ë‹ˆë‹¤ì²´'  # ë…ì ì§€í–¥
    }
}

# ê²€ì‚¬ ê²°ê³¼ ì €ì¥
issues = {
    'critical': [],  # ì¦‰ì‹œ ìˆ˜ì • í•„ìš”
    'warning': [],   # ì¼ê´€ì„± ê°œì„  ê¶Œì¥
    'info': []       # ì°¸ê³  ì‚¬í•­
}

def check_hardcoded_colors(file_path: str, soup: BeautifulSoup):
    """hardcoded ìƒ‰ìƒ ê²€ì‚¬"""
    style_tags = soup.find_all('style')

    for style in style_tags:
        content = style.string
        if not content:
            continue

        # hex ìƒ‰ìƒ ì°¾ê¸°
        hex_colors = re.findall(r'#[0-9A-Fa-f]{6}', content)
        for color in hex_colors:
            # í† í° ì •ì˜ë¶€ëŠ” ì œì™¸
            if ':root' in content or 'CSS Custom Properties' in content:
                continue

            issues['warning'].append({
                'file': file_path,
                'type': 'hardcoded_color',
                'value': color,
                'message': f'Hardcoded color {color} â€” í† í°ìœ¼ë¡œ ë³€í™˜ ê¶Œì¥'
            })

def check_navy_usage(file_path: str, soup: BeautifulSoup):
    """navy ìƒ‰ìƒ ê¸ˆì§€ íŒ¨í„´ ê²€ì‚¬"""
    style_tags = soup.find_all('style')

    for style in style_tags:
        content = style.string
        if not content:
            continue

        if 'var(--navy)' in content:
            # í—ˆìš© íŒ¨í„´ ì²´í¬
            if '::selection' in content or 'blockquote' in content:
                continue

            issues['critical'].append({
                'file': file_path,
                'type': 'prohibited_navy',
                'message': 'var(--navy) ê¸ˆì§€ íŒ¨í„´ ë°œê²¬ â€” ::selection/blockquoteë§Œ í—ˆìš©'
            })

def check_nav_structure(file_path: str, soup: BeautifulSoup):
    """nav êµ¬ì¡° ì¼ê´€ì„± ê²€ì‚¬"""
    nav = soup.find('nav')
    if not nav:
        issues['warning'].append({
            'file': file_path,
            'type': 'missing_nav',
            'message': 'nav ìš”ì†Œ ì—†ìŒ'
        })
        return

    # nav ë§í¬ ì¶”ì¶œ
    links = nav.find_all('a')
    nav_items = [link.get_text(strip=True) for link in links]

    # í‘œì¤€ nav êµ¬ì¡°: Archive / Offering / About / Contact / Lab
    expected = ['Archive', 'Offering', 'About', 'Contact', 'Lab']

    if nav_items != expected and 'WOOHWAHAE' not in nav_items[0]:  # ë¡œê³ ëŠ” ì œì™¸
        issues['info'].append({
            'file': file_path,
            'type': 'nav_structure',
            'current': nav_items,
            'expected': expected,
            'message': 'nav êµ¬ì¡°ê°€ í‘œì¤€ê³¼ ë‹¤ë¦„'
        })

def check_meta_tags(file_path: str, soup: BeautifulSoup):
    """SEO/ë©”íƒ€íƒœê·¸ ê²€ì‚¬"""
    # og:tags
    og_title = soup.find('meta', property='og:title')
    og_desc = soup.find('meta', property='og:description')
    og_image = soup.find('meta', property='og:image')

    if not og_title:
        issues['warning'].append({
            'file': file_path,
            'type': 'missing_og_title',
            'message': 'og:title ì—†ìŒ'
        })

    if not og_desc:
        issues['warning'].append({
            'file': file_path,
            'type': 'missing_og_description',
            'message': 'og:description ì—†ìŒ'
        })

def check_font_usage(file_path: str, soup: BeautifulSoup):
    """í°íŠ¸ í† í° ì‚¬ìš© ê²€ì‚¬"""
    style_tags = soup.find_all('style')

    for style in style_tags:
        content = style.string
        if not content:
            continue

        # font-family ì§ì ‘ ì§€ì • ì°¾ê¸° (í† í° ì‚¬ìš© ê¶Œì¥)
        font_declarations = re.findall(r'font-family:\s*([^;]+);', content)

        for font in font_declarations:
            if 'var(--font-' not in font and 'inherit' not in font:
                # fallback ì²´í¬ (Pretendard, sans-serif ê°™ì€ êµ¬ì¡°ëŠ” í—ˆìš©)
                if ',' in font and 'sans-serif' in font:
                    continue

                issues['info'].append({
                    'file': file_path,
                    'type': 'direct_font',
                    'value': font.strip(),
                    'message': 'font-family ì§ì ‘ ì§€ì • â€” í† í° ì‚¬ìš© ê¶Œì¥'
                })

def check_accessibility(file_path: str, soup: BeautifulSoup):
    """ì ‘ê·¼ì„± ê²€ì‚¬"""
    # img alt ì²´í¬
    images = soup.find_all('img')
    for img in images:
        if not img.get('alt'):
            issues['warning'].append({
                'file': file_path,
                'type': 'missing_alt',
                'src': img.get('src', 'unknown'),
                'message': 'img alt ì†ì„± ì—†ìŒ'
            })

    # button aria-label ì²´í¬
    buttons = soup.find_all('button')
    for btn in buttons:
        text = btn.get_text(strip=True)
        if not text and not btn.get('aria-label'):
            issues['warning'].append({
                'file': file_path,
                'type': 'missing_aria_label',
                'message': 'buttonì— í…ìŠ¤íŠ¸/aria-label ì—†ìŒ'
            })

def audit_html_file(file_path: str):
    """ë‹¨ì¼ HTML íŒŒì¼ ê°ì‚¬"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        soup = BeautifulSoup(content, 'html.parser')

        # ê²€ì‚¬ ì‹¤í–‰
        check_hardcoded_colors(file_path, soup)
        check_navy_usage(file_path, soup)
        check_nav_structure(file_path, soup)
        check_meta_tags(file_path, soup)
        check_font_usage(file_path, soup)
        check_accessibility(file_path, soup)

    except Exception as e:
        issues['critical'].append({
            'file': file_path,
            'type': 'parse_error',
            'message': f'íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {str(e)}'
        })

def main():
    website_root = Path('/Users/97layer/97layerOS/website')

    # ìš°ì„ ìˆœìœ„ 1 â€” í•µì‹¬ í˜ì´ì§€
    priority_files = [
        'index.html',
        'about.html',
        'contact.html',
        'offering.html',
        'photography.html',
        'archive/index.html'
    ]

    print("ğŸ” WOOHWAHAE ì›¹ì‚¬ì´íŠ¸ ì „ìˆ˜ì¡°ì‚¬ ì‹œì‘\n")
    print("=" * 60)

    # 1ì°¨ ìš°ì„ ìˆœìœ„ íŒŒì¼ ê°ì‚¬
    print("\n[Phase 5] í•µì‹¬ í˜ì´ì§€ ê°ì‚¬ (6ê°œ)")
    for file in priority_files:
        file_path = website_root / file
        if file_path.exists():
            print(f"  â€¢ {file}")
            audit_html_file(str(file_path))

    # Archive ì—ì„¸ì´ ê°ì‚¬
    print("\n[Phase 5] Archive ì—ì„¸ì´ ê°ì‚¬")
    archive_dir = website_root / 'archive'
    essay_dirs = sorted([d for d in archive_dir.iterdir() if d.is_dir() and d.name.startswith('issue-')])

    for essay_dir in essay_dirs[:10]:  # ìµœëŒ€ 10ê°œ
        index_file = essay_dir / 'index.html'
        if index_file.exists():
            print(f"  â€¢ {essay_dir.name}/index.html")
            audit_html_file(str(index_file))

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print(f"\nğŸ“Š ê°ì‚¬ ê²°ê³¼ ìš”ì•½")
    print(f"  â€¢ CRITICAL (ì¦‰ì‹œ ìˆ˜ì •): {len(issues['critical'])}")
    print(f"  â€¢ WARNING (ê¶Œì¥ ìˆ˜ì •): {len(issues['warning'])}")
    print(f"  â€¢ INFO (ì°¸ê³ ): {len(issues['info'])}")

    # JSON ì €ì¥
    output_file = '/tmp/html_audit_report.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(issues, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ìƒì„¸ ë³´ê³ ì„œ: {output_file}")

    # Critical ì´ìŠˆ ì¦‰ì‹œ ì¶œë ¥
    if issues['critical']:
        print("\nğŸš¨ CRITICAL ì´ìŠˆ:")
        for issue in issues['critical'][:5]:
            print(f"  â€¢ [{issue['type']}] {issue['file']}")
            print(f"    â†’ {issue['message']}")

if __name__ == '__main__':
    main()
